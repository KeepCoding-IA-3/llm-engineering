{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnsHiqu48gzTP06NQmRg7m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install docling\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HEKW-7tUCVI","executionInfo":{"status":"ok","timestamp":1747855752991,"user_tz":-120,"elapsed":122999,"user":{"displayName":"Eric Risco de la Torre","userId":"16820333876295128124"}},"outputId":"fc251c2b-c88e-4545-bf29-0924f4e08e1c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting docling\n","  Downloading docling-2.33.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling) (4.13.4)\n","Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2025.4.26)\n","Collecting click<8.2.0 (from docling)\n","  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n","Collecting docling-core<3.0.0,>=2.29.0 (from docling-core[chunking]<3.0.0,>=2.29.0->docling)\n","  Downloading docling_core-2.31.1-py3-none-any.whl.metadata (6.0 kB)\n","Collecting docling-ibm-models<4.0.0,>=3.4.0 (from docling)\n","  Downloading docling_ibm_models-3.4.3-py3-none-any.whl.metadata (7.6 kB)\n","Collecting docling-parse<5.0.0,>=4.0.0 (from docling)\n","  Downloading docling_parse-4.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Collecting easyocr<2.0,>=1.7 (from docling)\n","  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n","Collecting filetype<2.0.0,>=1.2.0 (from docling)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.11/dist-packages (from docling) (0.31.2)\n","Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (5.4.0)\n","Collecting marko<3.0.0,>=2.1.2 (from docling)\n","  Downloading marko-2.1.3-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling) (3.1.5)\n","Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2.2.2)\n","Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (11.2.1)\n","Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.5.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (2.11.4)\n","Collecting pydantic-settings<3.0.0,>=2.3.0 (from docling)\n","  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting pylatexenc<3.0,>=2.10 (from docling)\n","  Downloading pylatexenc-2.10.tar.gz (162 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pypdfium2<5.0.0,>=4.30.0 (from docling)\n","  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-docx<2.0.0,>=1.1.2 (from docling)\n","  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n","Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n","  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from docling) (2.32.3)\n","Collecting rtree<2.0.0,>=1.3.0 (from docling)\n","  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.15.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.67.1)\n","Requirement already satisfied: typer<0.16.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from docling) (0.15.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.13.2)\n","Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling)\n","  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (4.23.0)\n","Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling)\n","  Downloading latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.1 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (6.0.2)\n","Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.9.0)\n","Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.29.0->docling)\n","  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.29.0->docling) (4.51.3)\n","Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: numpy<3.0.0,>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (2.0.2)\n","Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (4.11.0.86)\n","Requirement already satisfied: safetensors<1,>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.4.0->docling) (0.5.3)\n","Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (2.6.0+cu124)\n","Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (0.21.0+cu124)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.2)\n","Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n","  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (2.1.0)\n","Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n","  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Collecting ninja (from easyocr<2.0,>=1.7->docling)\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (24.2)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.0)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.3.0->docling)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n","  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.4.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16.0,>=0.12.5->docling) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16.0,>=0.12.5->docling) (13.9.4)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4.0.0,>=3.4.0->docling) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.24.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (2.19.1)\n","Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling)\n","  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.21.1)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.5.10)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.0.2)\n","Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.11/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.70.15)\n","Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.3.7)\n","Downloading docling-2.33.0-py3-none-any.whl (169 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docling_core-2.31.1-py3-none-any.whl (142 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docling_ibm_models-3.4.3-py3-none-any.whl (80 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docling_parse-4.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading marko-2.1.3-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n","Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n","Downloading latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pylatexenc\n","  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=416075fd8c65eccbebad4b4c337dd07bb5ea7e8a703ccd85ea40423b0a9bb736\n","  Stored in directory: /root/.cache/pip/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\n","Successfully built pylatexenc\n","Installing collected packages: python-bidi, pylatexenc, pyclipper, filetype, XlsxWriter, rtree, python-dotenv, python-docx, pypdfium2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mpire, marko, latex2mathml, jsonref, jsonlines, click, python-pptx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, semchunk, pydantic-settings, nvidia-cusolver-cu12, docling-core, docling-parse, easyocr, docling-ibm-models, docling\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: click\n","    Found existing installation: click 8.2.0\n","    Uninstalling click-8.2.0:\n","      Successfully uninstalled click-8.2.0\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed XlsxWriter-3.2.3 click-8.1.8 docling-2.33.0 docling-core-2.31.1 docling-ibm-models-3.4.3 docling-parse-4.0.1 easyocr-1.7.2 filetype-1.2.0 jsonlines-3.1.0 jsonref-1.1.0 latex2mathml-3.78.0 marko-2.1.3 mpire-2.10.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 pydantic-settings-2.9.1 pylatexenc-2.10 pypdfium2-4.30.1 python-bidi-0.6.6 python-docx-1.1.2 python-dotenv-1.1.0 python-pptx-1.0.2 rtree-1.4.0 semchunk-2.2.2\n"]}]},{"cell_type":"code","source":["from docling.document_converter import DocumentConverter\n","\n","source = \"https://arxiv.org/pdf/2504.21801v1\"  # document per local path or URL\n","converter = DocumentConverter()\n","result = converter.convert(source)\n","print(result.document.export_to_markdown())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRVJD3lMUGbh","executionInfo":{"status":"ok","timestamp":1747856030431,"user_tz":-120,"elapsed":277435,"user":{"displayName":"Eric Risco de la Torre","userId":"16820333876295128124"}},"outputId":"b9e1f292-2d97-42ec-f464-5d214a538df0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n","WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["<!-- image -->\n","\n","## DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition\n","\n","Z.Z. Ren*, Zhihong Shao*, Junxiao Song*, Huajian Xin † , Haocheng Wang , Wanjia Zhao , Liyue Zhang, Zhe Fu † † Qihao Zhu, Dejian Yang, Z.F. Wu, Zhibin Gou, Shirong Ma, Hongxuan Tang, Yuxuan Liu, Wenjun Gao Daya Guo, Chong Ruan\n","\n","DeepSeek-AI\n","\n","https://github.com/deepseek-ai/DeepSeek-Prover-V2\n","\n","## Abstract\n","\n","We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's stepby-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model. The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25). Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing.\n","\n","Figure 1 | Benchmark performance of DeepSeek-Prover-V2. On the AIME benchmark, DeepSeekV3 is evaluated using the standard find-answer task for natural-language reasoning, while prover models generate Lean code to construct formal proofs for a given correct answer.\n","\n","<!-- image -->\n","\n","## 1. Introduction\n","\n","The emergence of reasoning capabilities in large language models (LLMs) has revolutionized numerous areas of artificial intelligence, particularly in the domain of mathematical problem solving (DeepSeek-AI, 2025). These advancements are largely enabled by the paradigm of inference-time scaling, most notably through natural language chain-of-thought reasoning (Jaech et al., 2024). Rather than relying solely on a single forward pass to arrive at an answer, LLMs can reflect on intermediate reasoning steps, improving both accuracy and interpretability. Despite the success of natural language reasoning in solving competition-level mathematical problems, its application to formal theorem proving remains fundamentally challenging. LLMs perform natural language reasoning in an inherently informal manner, relying on heuristics, approximations, and data-driven guessing patterns that often lack the rigorous structure required by formal verification systems. In contrast, proof assistants such as Lean (Moura and Ullrich, 2021), Isabelle (Paulson, 1994), and Coq (Barras et al., 1999) operate on strict logical foundations, where every proof step must be explicitly constructed and formally verified. These systems permit no ambiguity, implicit assumptions, or omission of details. Bridging the gap between informal, high-level reasoning and the syntactic rigor of formal verification systems remains a longstanding research challenge in neural theorem proving (Yang et al., 2024).\n","\n","To harness the strengths of informal mathematical reasoning in support of formal theorem proving, a classical approach is to hierarchically decompose formal proofs based on the guidance of natural-language proof sketches. Jiang et al. (2023) proposed a framework, called Draft, Sketch, and Prove (DSP), that leverages a large language model to generate proof sketches in natural language, which are subsequently translated into formal proof steps. This informal-to-formal theorem proving paradigm closely mirrors the concept of subgoals in hierarchical reinforcement learning (Barto and Mahadevan, 2003; Nachum et al., 2018; Eppe et al., 2022), where complex tasks are broken down into a hierarchy of simpler subtasks that can be solved independently to progressively achieve the overarching objective. In formal theorem proving, a subgoal is typically an intermediate proposition or lemma that contributes to the proof of a larger theorem (Zhao et al., 2023, 2024). This hierarchical decomposition aligns with human problemsolving strategies and supports modularity, reusability, and more efficient proof search (Wang et al., 2024b; Zheng et al., 2024). Recent studies have extended this paradigm by employing multi-tiered hierarchies for structured proof generation (Wang et al., 2024a), and by leveraging reinforcement learning techniques to optimize the decomposition of complex theorems into manageable subgoals (Dong et al., 2024).\n","\n","In this paper, we develop a reasoning model for subgoal decomposition, leveraging a suite of synthetic cold-start data and large-scale reinforcement learning to enhance its performance. To construct the cold-start dataset, we develop a simple yet effective pipeline for recursive theorem proving, utilizing DeepSeek-V3 (DeepSeek-AI, 2024) as a unified tool for both subgoal decomposition and formalization. We prompt DeepSeek-V3 to decompose theorems into high-level proof sketches while simultaneously formalizing these proof steps in Lean 4, resulting in a sequence of subgoals. Since the subgoal decomposition is powered by a large general-purpose model, we use a smaller 7B model to handle the proof search for each subgoal, thereby reducing the associated computational burden. Additionally, we introduce a curriculum learning framework that leverages the decomposed subgoals to generate conjectural theorems, progressively increasing the difficulty of training tasks to better guide the model's learning process. Once the decomposed steps of a challenging problem are resolved, we pair the complete step-by-step formal proof with the corresponding chain-of-thought from DeepSeek-V3 to create cold-start reasoning data. Based on the cold start, a subsequent reinforcement learning stage is applied to further strengthen\n","\n","Figure 2 | Overview of the cold-start data collection process employed by DeepSeek-Prover-V2. We first prompt DeepSeek-V3 to generate a natural-language proof sketch while simultaneously formalizing it into a Lean statement with sorry placeholders for omitted proof details. A 7B prover model then recursively solves the decomposed subgoals. By combining these subgoal proofs, we construct a complete formal proof for the original complex problem. This composed proof is appended to DeepSeek-V3's original chain-of-thought, creating high-quality cold-start training data for formal mathematical reasoning.\n","\n","<!-- image -->\n","\n","the connection between informal mathematical reasoning and formal proof construction. Our experiments show that reinforcement learning starting from the cold start of informal reasoning in task decomposition significantly enhances the model's capabilities in formal theorem proving. The resulting DeepSeek-Prover-V2-671B model establishes a new state-of-the-art in neural theorem proving across multiple benchmarks. On MiniF2F-test, it achieves 82.4% accuracy with Pass@32, improving to 88.9% with Pass@8192. The model shows strong generalization capabilities to college-level theorem proving, solving 37.1% of ProofNet-test problems with Pass@1024 and tackling 49 out of 658 challenging PutnamBench problems. Additionally, we contribute ProverBench, a benchmark dataset containing 325 formalized problems to advance neural theorem proving research, including 15 from the prestigious AIME competitions (years 24-25). DeepSeek-Prover-V2-671B successfully solves 6 of these 15 challenging AIME problems, further demonstrating its sophisticated mathematical reasoning capabilities.\n","\n","## 2. Method\n","\n","## 2.1. Recursive Proof Search via Subgoal Decomposition\n","\n","Decomposing the proof of a complex theorem into a sequence of smaller lemmas that serve as stepping stones is an effective strategy commonly employed by human mathematicians. Several previous studies have explored this hierarchical strategy in the context of neural theorem proving, aiming to enhance proof search efficiency by leveraging the informal reasoning capabilities of modern LLMs (Jiang et al., 2023; Zhao et al., 2023; Wang et al., 2024a; Dong et al., 2024). In this paper, we develop a simple yet effective pipeline that utilizes DeepSeek-V3 (DeepSeek-AI, 2024) as a unified tool for subgoal decomposition in formal theorem proving.\n","\n","Figure 3 | An illustrative example of how we translate decomposed subgoals into a series of lemma statements. We first (a) replace the original goal state and then (b) incorporate preceding subgoals as premises. Statement type (b) is used for recursive solving of complex problems, while both types (a) and (b) are incorporated into the curriculum learning process.\n","\n","<!-- image -->\n","\n","<!-- image -->\n","\n","Sketching Formal Proofs from Natural Language Reasoning. Recent advances in large language models have led to significant breakthroughs in informal reasoning capabilities. To bridge the gap between formal and informal reasoning, we leverage cutting-edge general-purpose LLMs, recognized for their strong mathematical reasoning and instruction-following abilities, to construct the foundational framework of our theorem-proving system. Our findings indicate that off-the-shelf models, such as DeepSeek-V3 (DeepSeek-AI, 2024), are capable of decomposing proof steps and expressing them in formal languages. To prove a given formal theorem statement, we prompt DeepSeek-V3 to first analyze the mathematical problem in natural language, then decompose the proof into smaller steps, translating each step into a corresponding Lean formal statement. Since general-purpose models are known to struggle with producing complete Lean proofs, we instruct DeepSeek-V3 to generate only a high-level proof sketch with the details omitted. The resulting chain of thought culminates in a Lean theorem composed of a sequence of have statements, each concluded with a sorry placeholder indicating a subgoal to be solved. This approach mirrors the human style of proof construction, in which a complex theorem is incrementally reduced to a sequence of more manageable lemmas.\n","\n","Recursive Resolution of Subgoals. Leveraging the subgoals generated by DeepSeek-V3, we adopt a recursive solving strategy to systematically resolve each intermediate proof step. We extract subgoal expressions from have statements to substitute them for the original goals in the given problems (see Figure 3(a)), and then incorporate the preceding subgoals as premises (see Figure 3(b)). This construction enables subsequent subgoals to be resolved using the intermediate results of earlier steps, thereby promoting a more localized dependency structure and facilitating the development of simpler lemmas. To reduce the computational overhead of extensive proof search, we employ a smaller 7B prover model specifically optimized for processing the decomposed lemmas. Upon the successful resolution of all decomposed steps, a complete proof of the original theorem can be automatically derived.\n","\n","Curriculum Learning for Subgoal-based Theorem Proving. The training of prover models requires large formal-language problem sets, typically derived by formalizing existing naturallanguage mathematical corpora (Xin et al., 2024a; Ying et al., 2024; Lin et al., 2025). Although formalization of human-authored texts provides high-quality and diverse formal content, the resulting training signals for prover models are often sparse, as a large proportion of computa-\n","\n","tional attempts do not yield successful proofs and therefore offer no positive reward signals. To generate denser training signals, Dong and Ma (2025) proposed a self-play approach that enriches training problem sets by generating tractable conjectures closely related to the original theorem statements, thereby enabling more efficient use of training compute. In this paper, we implement a straightforward approach that leverages subgoals to expand the scope of formal statements used for model training. We generate two types of subgoal theorems, one incorporating preceding subgoals as premises and one without, corresponding to Figure 3(b) and Figure 3(a), respectively. Both types are integrated into the expert iteration stage (Polu and Sutskever, 2020), establishing a curriculum that progressively guides the prover model toward systematically addressing a curated subset of challenging problems. This procedure builds on the same underlying principle as AlphaProof's test-time reinforcement learning (DeepMind, 2024), wherein variations of a target problem are generated to enhance the model's capability in solving challenging IMO-level problems.\n","\n","## 2.2. Unifying Informal Reasoning and Proof Formalization\n","\n","The algorithmic framework discussed above operates in two stages, leveraging two complementary models: DeepSeek-V3 for lemma decomposition and a 7B prover model to complete the corresponding formal proof details. This pipeline provides a natural and scalable mechanism for synthesizing formal reasoning data by combining high-level reasoning from language models with precise formal verification. In this manner, we unify the capabilities of informal mathematical reasoning and proof formalization within a single model.\n","\n","Cold Start by Synthetic Data. Wecurate a subset of challenging problems that remain unsolved by the 7B prover model in an end-to-end manner, but for which all decomposed subgoals have been successfully resolved. By composing the proofs of all subgoals, we construct a complete formal proof for the original problem. This proof is then appended to DeepSeek-V3's chain-ofthought, which outlines the corresponding lemma decomposition, thereby producing a cohesive synthesis of informal reasoning and subsequent formalization. It enables the collection of hundreds of high-quality synthetic cold-start data, which serve as the foundation for training DeepSeek-Prover-V2. This cold-start dataset generation strategy differs from that of KiminaProver (Wang et al., 2025), a concurrent work on formal reasoning models. Specifically, we synthesize data by formalizing natural-language proofs directly into structured formal proof sketches. In contrast, Kimina-Prover adopts a reverse workflow: it begins by collecting complete formal proofs alongside their informal counterparts, then uses general-purpose reasoning models to retrosynthesize intermediate natural-language reasoning steps into coherent thinking blocks.\n","\n","Reasoning-oriented Reinforcement Learning. After fine-tuning the prover model on the synthetic cold-start data, we perform a reinforcement learning stage to further enhance its ability to bridge informal reasoning with formal proof construction. Following the standard training objective for reasoning models (DeepSeek-AI, 2025), we use binary correct-or-incorrect feedback as the primary form of reward supervision. During the training process, we observe that the structure of the generated proofs frequently diverges from the lemma decomposition provided by the chain-of-thought guidance. To address this issue, we incorporate a consistency reward in the early steps of training, which penalizes the structural misalignment, explicitly enforcing the inclusion of all decomposed have -structured lemmas in the final proof. In practice, enforcing this alignment enhances proof accuracy, especially on complex theorems that demand multi-step reasoning.\n","\n","## 2.3. Training Details of DeepSeek-Prover-V2\n","\n","Two-Stage Training. DeepSeek-Prover-V2 is developed through a two-stage training pipeline that establishes two complementary proof generation modes:\n","\n","- 1. High-efficiency non-Chain-of-Thought (non-CoT) mode: This mode is optimized for the rapid generation of formal Lean proof codes, focusing on producing concise proofs without explicit intermediate reasoning steps.\n","- 2. High-precision Chain-of-Thought (CoT) mode: This mode systematically articulates intermediate reasoning steps, emphasizing transparency and logical progression, before constructing the final formal proofs.\n","\n","Consistent with DeepSeek-Prover-V1.5 (Xin et al., 2024b), these two generation modes are governed by two distinct guiding prompts (see Appendix A for examples). In the first stage, we employ expert iteration within a curriculum learning framework to train a non-CoT prover model, meanwhile, synthesizing proofs for hard problems through subgoal-based recursive proving. The non-CoT generation mode is chosen to accelerate iterative training and data collection processes, as it offers significantly faster inference and validation cycles. Building on this foundation, the second stage leverages cold-start chain-of-thought (CoT) data synthesized by integrating DeepSeek-V3's sophisticated mathematical reasoning patterns with our synthetic formal proofs. The CoT mode is enhanced through a further reinforcement learning stage, following the standard training pipeline commonly used for reasoning models.\n","\n","Expert Iteration. The training procedure for the non-CoT mode of DeepSeek-Prover-V2 follows the paradigm of expert iteration (Polu and Sutskever, 2020), a widely adopted framework for developing formal theorem provers. In each training iteration, the current best prover policy is used to generate proof attempts for those challenging problems that remain unsolved in prior iterations. Those successful attempts, verified by Lean proof assistant, are incorporated into the SFT dataset to train an improved model. This iterative loop ensures that the model not only learns from the initial demonstration datasets but also distills its own successful reasoning traces, progressively refining its ability to solve harder problems. The overall training procedure remains largely aligned with that of DeepSeek-Prover-V1 (Xin et al., 2024a) and DeepSeek-ProverV1.5 (Xin et al., 2024b), with only two modifications to the distribution of training problems. First, we incorporate additional problems derived from autoformalization and various opensource datasets (Ying et al., 2024; Dong and Ma, 2025; Lin et al., 2025), broadening the coverage of the training problem domains. Second, we augment the dataset with problems generated through subgoal decomposition, aiming at solving more challenging instances from the valid split of the MiniF2F benchmark (Zheng et al., 2022).\n","\n","Supervised Fine-tuning. We perform supervised fine-tuning on DeepSeek-V3-Base-671B (DeepSeek-AI, 2024) using a constant learning rate of 5e-6 within a context window of 16,384 tokens. Our training corpus consists of two complementary sources: (1) non-CoT data collected through expert iteration, which produces Lean codes without intermediate reasoning steps; and (2) the cold-start CoT data described in Section 2.2, which distills DeepSeek-V3's advanced mathematical reasoning processes into structured proving pathways. The non-CoT components emphasize formal verification skills in the Lean theorem prover ecosystem, while the CoT examples explicitly model the cognitive process of transforming mathematical intuition into formal proof structures.\n","\n","Reinforcement Learning. We employ Group Relative Policy Optimization (GRPO; Shao et al., 2024) as our reinforcement learning algorithm, which has demonstrated superior effectiveness and efficiency in reasoning tasks (DeepSeek-AI, 2025). Unlike PPO (Schulman et al., 2017), GRPO eliminates the need for a separate critic model by sampling a group of candidate proofs for each theorem prompt and optimizing the policy based on their relative rewards. Training utilizes binary rewards, where each generated Lean proof receives a reward of 1 if verified as correct and 0 otherwise. To ensure effective learning, we curate training prompts to include only problems that are sufficiently challenging yet solvable by the supervised fine-tuned model. During each iteration, we sample 256 distinct problems, generating 32 candidate proofs per theorem with a maximum sequence length of 32,768 tokens.\n","\n","Distillation. We extend the maximum context length of DeepSeek-Prover-V1.5-Base-7B (Xin et al., 2024b) from 4,096 to 32,768 tokens and fine-tune this extended-context model using rollout data collected during the reinforcement learning phase of DeepSeek-Prover-V2-671B. Alongside the CoT reasoning mode, we incorporate non-CoT proof data collected during expert iteration to enable a cost-efficient proving option that produces concise formal outputs with a small-size model. In addition, we perform the same reinforcement learning stage used in the training of the 671B model to boost the performance of DeepSeek-Prover-V2-7B.\n","\n","## 3. Experimental Results\n","\n","In this section, we present a systematic evaluation of DeepSeek-Prover-V2 across diverse benchmark datasets of formal theorem proving, covering both high school competition problems and undergraduate-level mathematics. All experimental results of DeepSeek-Prover-V2 are conducted with Lean 4.9.0, using the same testing environment as DeepSeek-Prover-V1.5 (Xin et al., 2024b). Without further specification, baseline evaluation results are sourced from their respective original papers.\n","\n","## 3.1. Results on MiniF2F Benchmark\n","\n","MiniF2F (Zheng et al., 2022) consists of 488 formalized problem statements sourced from a diverse range of mathematical materials, including the AIME, AMC, and IMO competitions, along with selected problems from the MATH dataset (Hendrycks et al., 2021). The benchmark includes Olympiad-level problems covering core areas of elementary mathematics, including algebra, number theory, and induction. These problems are divided into two equally sized subsets, denoted by miniF2F-valid and miniF2F-test, each containing 244 problems with an identical distribution across subject areas. We reserve the miniF2F-test set exclusively for evaluating model performance, while the miniF2F-valid problems are incorporated into curriculum learning with subgoal decomposition. We adopt the revised version of miniF2F released by Wang et al. (2025), and further introduce two additional revisions to miniF2F-valid and one revision to miniF2F-test (see Appendix C).\n","\n","Comparison with SoTA Models. Table 1 summarizes a comparison of state-of-the-art formal theorem-proving modeling evaluated on the miniF2F-test dataset. The experimental results demonstrate that DeepSeek-Prover-V2-671B establishes a new state-of-the-art performance on the miniF2F-test benchmark, achieving an unprecedented 82.4% accuracy with only 32 samples when leveraging the CoT generation strategy. Notably, the more parameter-efficient\n","\n","| Method                                                                                                                                                                        | Model size    | Sample budget                                         | miniF2F-test                                              |\n","|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|-------------------------------------------------------|-----------------------------------------------------------|\n","| Tree Search Methods                                                                                                                                                           |               |                                                       |                                                           |\n","| Hypertree Proof Search (Lample et al., 2022) InternLM2.5-StepProver + BFS + CG (Wu et al., 2024) HunyuanProver v16 + BFS + DC (Li et al., 2024) BFS-Prover (Xin et al., 2025) | 600M 7B 7B 7B | 64 × 5000 256 × 32 × 600 600 × 8 × 400 2048 × 2 × 600 | 41.0% 65.9% 68.4% 70.83% ± 0.89%                          |\n","| Whole-proof Generation Methods                                                                                                                                                |               |                                                       |                                                           |\n","| Leanabell-Prover-GD-RL (Zhang et al., 2025) Goedel-Prover-SFT (Lin et al., 2025) STP (Dong and Ma, 2025)                                                                      | 7B 7B 7B      | 128 25600 25600                                       | 61.1% 64.7% 67.6%                                         |\n","| Kimina-Prover-Preview-Distill (Wang et al., 2025)                                                                                                                             |               | 1 32                                                  | 52.5% 63.1%                                               |\n","|                                                                                                                                                                               | 7B            | 1024                                                  | 70.8%                                                     |\n","| Kimina-Prover-Preview (Wang et al., 2025)                                                                                                                                     | 72B           | 32 1024 8192 1 32 1024 8192                           | 68.85% 77.87% 80.74% 55.5% ± 68.0% ±                      |\n","| DeepSeek-Prover-V2 (non-CoT)                                                                                                                                                  | 7B            | 1 32 1024                                             | 73.2% ± 75.0%                                             |\n","|                                                                                                                                                                               |               |                                                       | 1.4% 59.5% ± 73.8% ±                                      |\n","|                                                                                                                                                                               |               | 8192                                                  | 0.5% 0.5% 1.4% 0.4% 76.7% ± 0.2% 78.3%                    |\n","|                                                                                                                                                                               |               | 1                                                     |                                                           |\n","| DeepSeek-Prover-V2 (CoT)                                                                                                                                                      | 671B          |                                                       |                                                           |\n","|                                                                                                                                                                               | 7B            | 32 1024 8192 1                                        | 58.6% ± 1.1% 75.6% ± 0.5% 79.9% ± 0.3% 82.0% 61.9% ± 1.6% |\n","|                                                                                                                                                                               | 671B          | 32 1024                                               | 82.4% ± 0.6% 86.6% ± 0.3%                                 |\n","\n","Table 1 | Comparison with state-of-the-art models on the miniF2F-test dataset. The notation 𝜇 ± 𝜎 denotes the average accuracy 𝜇 and the standard deviation 𝜎 . The tags CoT and non-CoT refer to two generation modes of a unified model, each guided by a different prompt.\n","\n","| Problem Category   | Problem Category   | miniF2F-valid curriculum (+Pass@8192)                 | miniF2F-test Pass@8192                          |\n","|--------------------|--------------------|-------------------------------------------------------|-------------------------------------------------|\n","| Olympiad           | IMO AIME           | 10 / 20 = 50.0% 10 (+ 2 )/ 15 = 80.0% 39 / 45 = 86.7% | 10 / 20 = 50.0% 14 / 15 = 93.3% 35 / 45 = 77.8% |\n","|                    | AMC                |                                                       |                                                 |\n","| MATH               | Algebra            | 69 / 70 = 98.6%                                       | 70 / 70 = 100.0%                                |\n","| MATH               | Number Theory      | 58 / 60 = 96.7%                                       | 58 / 60 = 96.7%                                 |\n","| Custom             | Algebra            | 18 / 18 = 100.0%                                      | 15 / 18 = 83.3%                                 |\n","| Custom             | Number Theory      | 8 / 8 = 100.0%                                        | 7 / 8 = 87.5%                                   |\n","| Custom             | Induction          | 8 / 8 = 100.0%                                        | 8 / 8 = 100.0%                                  |\n","| Overall Pass Rate  | Overall Pass Rate  | 220 (+ 2 )/ 244 = 91 . 0 %                            | 217 / 244 = 88 . 9 %                            |\n","\n","Table 2 | Problems solved by DeepSeek-Prover-V2-671B on the miniF2F benchmark. Results on miniF2F-valid are collected throughout the curriculum learning process, and DeepSeek-ProverV2-671B is further invoked with Pass@8192 on the remaining problems.\n","\n","DeepSeek-Prover-V2-7B also exhibits competitive performance, surpassing all existing opensource theorem provers in the literature. The comparative analysis further reveals a compelling scaling pattern: as the sample budget increases from 1 to 8192, the performance gap between the 7B and 671B variants widens considerably, with the larger model demonstrating superior sample efficiency and a steeper improvement trajectory.\n","\n","Proving Challenging Problems through Subgoal-guided Curricula. Table 2 presents a detailed breakdown of the problems solved by DeepSeek-Prover-V2 on the miniF2F benchmark, where it achieves strong overall performance with a 91.0% pass rate on the validation set and 88.9% on the test set. Remarkably, our subgoal-guided curriculum learning framework, which integrates the general-purpose model DeepSeek-V3 with a lightweight specialized 7B prover, achieves a 90.2% success rate on miniF2F-valid, nearly matching the performance of DeepSeekProver-V2-671B. These findings highlight the potential of state-of-the-art general-purpose LLMs to extend beyond natural language understanding and effectively support complex formal reasoning tasks. Through strategic subgoal decomposition, the model is able to break down challenging problems into a sequence of tractable steps, serving as an effective bridge between informal reasoning and formal proof construction.\n","\n","CoT vs. non-CoT. The experimental results in Table 1 demonstrate a substantial performance advantage of the CoT reasoning mode over the non-CoT mode in formal mathematical reasoning. This reinforces the effectiveness of CoT prompting, which encourages decomposition of complex problems into intermediate steps, and further confirms that inference-\n","\n","| # output tokens   |   non-CoT |    CoT |\n","|-------------------|-----------|--------|\n","| 7B                |     442.6 | 4488.5 |\n","| 671B              |     761.8 | 6751.9 |\n","\n","Table 3 | Average number of tokens generated by DeepSeek-Prover-V2 on miniF2F-test.\n","\n","time scaling holds in the domain of formal theorem proving. Complementing these findings, Table 3 provides statistics on the number of tokens generated by DeepSeek-Prover-V2 under different reasoning modes. As expected, the CoT mode produces significantly longer outputs, reflecting its sophisticated reasoning process. Interestingly, within the non-CoT setting, the 671B model generates longer outputs on average compared to the 7B model. A closer examination reveals that, although explicit reasoning is not prompted in the non-CoT mode, the larger model often inserts brief natural language comments within the proof code that resemble implicit reasoning steps (see Appendix A). This suggests that high-capacity models may internalize and externalize intermediate reasoning implicitly, even in the absence of explicit CoT prompting\n","\n","## 3.2. Results on Undergraduate-level Benchmarks\n","\n","ProofNet (Azerbayev et al., 2023) consists of 371 problems in Lean 3, drawn from a range of popular undergraduate pure mathematics textbooks, covering topics such as real and complex analysis, linear algebra, abstract algebra, and topology. We use the Lean 4 translation of ProofNet made available by Xin et al. (2024b), which is further divided into two splits: ProofNet-valid and ProofNet-test, containing 185 and 186 problems, respectively. The test split of ProofNet is reserved exclusively for model evaluation, as variants of the ProofNet-valid problems are included in the public synthetic dataset provided by Dong and Ma (2025), which is used in our supervised fine-tuning. The results, shown in Table 4, indicate a substantial improvement in the pass rate of DeepSeek-Prover-V2 when using CoT reasoning compared to the nonCoT setting. Notably, despite the training data being predominantly drawn from high-school\n","\n","Table 4 | The experimental results on ProofNet-test and PutnamBench. The scores for GoedelProver-SFT and STP on PutnamBench are sourced from their original papers, which conducted evaluations on an earlier version of PutnamBench comprising 644 problems.\n","\n","| Method                               | Model size   | Sample budget    | ProofNet-test                                | PutnamBench                        |\n","|--------------------------------------|--------------|------------------|----------------------------------------------|------------------------------------|\n","| Goedel-Prover-SFT (Lin et al., 2025) | 7B           | 32 512           | 15.6% -                                      | 6 / 644 7 / 644                    |\n","| STP (Dong and Ma, 2025)              | 7B           | 128 3200 25600   | 19.5% ± 0.7% 23.9% ± 0.6% 26.9%              | 7 / 644 8 / 644 -                  |\n","| DeepSeek-Prover-V2 (non-CoT)         | 7B           | 32 128 1024 32   | 21.6% ± 0.2% 23.1% ± 0.6% 24.7% 23.8% ± 0.2% | 11 / 658 15 / 658 23 / 658 9 / 658 |\n","| DeepSeek-Prover-V2 (CoT)             | 7B           | 1024 32 128 1024 | 31.2% 23.0% ± 0.4% 25.4% ± 0.7% 29.6%        | 16 / 658 9 / 658 10 / 658 11 / 658 |\n","|                                      | 671B         | 32 128 1024      | 30.5% ± 0.7% 33.6% ± 0.3% 37 . 1 %           | 22 / 658 33 / 658 49 / 658         |\n","\n","level mathematics, the model exhibits strong generalization to more advanced, college-level mathematical problems, underscoring its robust formal reasoning capabilities.\n","\n","PutnamBench (Tsoukalas et al., 2024) is a continuously updated benchmark featuring competition mathematics problems from the William Lowell Putnam Mathematical Competition , spanning the years 1962 to 2023. The Putnam Competition is a highly prestigious annual mathematics competition for undergraduate students across the United States and Canada, encompassing a variety of college-level domains such as analysis, linear algebra, abstract algebra, combinatorics, probability, and set theory. We evaluate our model on the latest release of PutnamBench, which contains 658 problems formalized in Lean 4. We exclude problems that are incompatible with Lean 4.9.0 and evaluate the model on the remaining set of 649 problems. As shown in Table 4, DeepSeek-Prover-V2-671B demonstrates enhanced reasoning capabilities in the PutnamBench, solving 49 problems and significantly outperforming its non-CoT counterpart. These results further highlight the effectiveness of the CoT reasoning approach in handling challenging, college-level mathematical problems.\n","\n","Skill Discovery by Reinforcement Learning. An unexpected finding in our evaluation is the exceptional performance of DeepSeek-Prover-V2-7B with non-CoT generation mode on the PutnamBench dataset. Remarkably, this smaller 7B model successfully solves 13 problems that remain unsolved by its larger counterpart, DeepSeek-Prover-V2-671B, raising our total number of solved problems on PutnamBench from 49 to 62 out of 658. Upon closer examination of the model's outputs, we identified a distinctive pattern in its reasoning approach: the 7B model frequently employs Cardinal.toNat and Cardinal.natCast\\_inj to handle problems involving finite cardinalities (see examples in Appendix B), which are noticeably absent in the outputs generated by the 671B version. This technique appears to enable the model to effectively solve a subset of problems that require nuanced manipulation of cardinal values.\n","\n","| Method                       |            | Sample budget   | ProverBench   | ProverBench   |\n","|------------------------------|------------|-----------------|---------------|---------------|\n","|                              | Model size |                 | All           | AIME 24&25    |\n","|                              |            | 32              | 27.5% ± 0.7%  | 0 / 15        |\n","| STP (Dong and Ma, 2025)      | 7B         | 128             | 31.4% ± 1.1%  | 1 / 15        |\n","|                              |            | 512             | 36.3%         | 1 / 15        |\n","|                              |            | 32              | 47.7% ± 0.6%  | 1 / 15        |\n","|                              | 7B         | 128             | 48.8% ± 0.2%  | 1 / 15        |\n","|                              |            | 512             | 49.5%         | 1 / 15        |\n","| DeepSeek-Prover-V2 (non-CoT) |            | 32              | 49.5% ± 0.5%  | 1 / 15        |\n","|                              | 671B       | 128             | 51.5% ± 0.3%  | 2 / 15        |\n","|                              |            | 512             | 52.3%         | 2 / 15        |\n","|                              |            | 32              | 49.0% ± 0.3%  | 1 / 15        |\n","|                              | 7B         | 128             | 50.8% ± 0.5%  | 1 / 15        |\n","|                              |            | 512             | 51.7%         | 1 / 15        |\n","| DeepSeek-Prover-V2 (CoT)     |            | 32              | 52.9% ± 0.9%  | 4 / 15        |\n","|                              | 671B       | 128             | 56.5% ± 0.5%  | 5 / 15        |\n","|                              |            | 512             | 59 . 1 %      | 6 / 15        |\n","\n","Table 6 | The experimental results on ProverBench. The All category represents the complete evaluation set consisting of 325 problems, while AIME 24&amp;25 denotes a subset of 15 problems formalized from recent AIME competitions. The results for STP (Dong and Ma, 2025) are evaluated using the open-source model weights.\n","\n","## 3.3. Results on Combinatorial Problems\n","\n","CombiBench (Liu et al., 2025) is a comprehensive benchmark comprising 100 combinatorial competition problems formalized in Lean 4, each paired with its corresponding natural-language statement. We evaluate DeepSeek-Prover-V2 in the with-solution setting of this benchmark, where the correct answer is embedded in the Lean statement, allowing the evaluation to focus solely on proof generation. After filtering out problems incompatible with Lean 4.9.0 and\n","\n","| CombiBench                                | CombiBench                                | Pass@16          |\n","|-------------------------------------------|-------------------------------------------|------------------|\n","| Kimina-Prover-Preview (Wang et al., 2025) | Kimina-Prover-Preview (Wang et al., 2025) | 7 / 100          |\n","| DeepSeek-Prover-V2-7B                     | non-CoT CoT                               | 8 / 100 10 / 100 |\n","| DeepSeek-Prover-V2-671B                   | non-CoT CoT                               | 9 / 100 12 / 100 |\n","\n","Table 5 | Evaluation results on CombiBench under the with-solution setting.\n","\n","those containing multiple sorry placeholders, we evaluate on 77 problems from the benchmark and successfully solve 12 of them. These results indicate that, while the prover model is primarily trained in number theory and algebra, it demonstrates promising generalization to combinatorial problems, despite their persistent difficulty.\n","\n","## 3.4. ProverBench: Formalization of AIME and Textbook Problems\n","\n","To enhance existing benchmarks and advance research in formal theorem proving, we introduce a benchmark dataset comprising 325 problems. Of these, 15 are formalized from number theory and algebra questions featured in the recent AIME competitions (AIME 24 and 25), offering authentic high-school competition-level challenges. The remaining 310 problems are drawn from curated textbook examples and educational tutorials, contributing a diverse and pedagogically grounded collection of formalized mathematical problems. This benchmark is designed to enable more comprehensive evaluation across both high-school competition problems and undergraduate-level mathematics.\n","\n","AIME Formalization. The American Invitational Mathematics Examination (AIME) is an annual mathematics competition designed to challenge and recognize talented high school students who demonstrate exceptional proficiency in mathematics. The problems from AIME 24&amp;25 have become a standard benchmark for evaluating the reasoning capabilities of large language models. In order to bridge the evaluation of model performance across formal and informal mathematical reasoning, we curate and formalize a subset of problems from AIME 24&amp;25. To ensure cleaner formaliza-\n","\n","Table 7 | Selection of AIME 24&amp;25 problems for formalization. Problems with underlined bolded indices have been solved by DeepSeek-ProverV2. Problems solved by DeepSeek-V3-0324 using Maj@16 are highlighted with a gray background.\n","\n","| Contest   | Problems           |\n","|-----------|--------------------|\n","| AIME 24I  | P2 , P7 , P13      |\n","| AIME 24II | P4 , P7, P13 , P14 |\n","| AIME 25I  | P1 , P8 , P9, P11  |\n","| AIME 25II | P2 , P4 , P13, P15 |\n","\n","tions, we filter out geometry, combinatorics, and counting problems whose representations in Lean are potentially cumbersome. This results in 15 selected problems, covering competitionlevel topics in elementary number theory and algebra. We evaluate DeepSeek-V3-0324 on the selected set of problems using the standard find-answer task for natural-language mathematical reasoning. With majority voting over 16 sampled responses, the model successfully solves 8 out of 15 problems. In comparison, DeepSeek-Prover-V2-671B, operating under the formal proof generation setting with given correct answers, is able to construct valid formal proofs for 6 of 15 problems. This comparison highlights that the performance gap between informal mathematical reasoning and formal theorem proving is substantially narrowing, indicating growing alignment between linguistic understanding and formal logical rigor in advanced language models.\n","\n","Textbook Formalization. In addition to AIME 24&amp;25, we augment our benchmark with problems carefully selected from textbooks used in high school competitions and undergraduatelevel courses to strengthen coverage in specific mathematical domains. This curation process ensures comprehensive representation across difficulty levels and topic areas. As a result, we formalize 310 problems that encompass a broad spectrum, ranging from elementary mathematics at the competition level to advanced topics typically encountered in undergraduate studies. This comprehensive benchmark covers number theory, elementary algebra, linear algebra, abstract algebra, calculus, real analysis, complex analysis, functional analysis, and probability. The deliberate inclusion of this diverse array of mathematical fields allows for a thorough assessment of model capabilities across varying levels of abstraction\n","\n","| Area                |   Count |\n","|---------------------|---------|\n","| AIME 24&25          |      15 |\n","| Number Theory       |      40 |\n","| Elementary Algebra  |      30 |\n","| Linear Algebra      |      50 |\n","| Abstract Algebra    |      40 |\n","| Calculus            |      90 |\n","| Real Analysis       |      30 |\n","| Complex Analysis    |      10 |\n","| Functional Analysis |      10 |\n","| Probability         |      10 |\n","| Total               |     325 |\n","\n","Table 8 | Distribution of mathematical areas represented in ProverBench.\n","\n","and reasoning styles. Number theory and algebra problems test a model's facility with discrete structures and equations, while analysis-oriented problems evaluate understanding of limits, continuity, and calculus. The abstract algebra and functional analysis components challenge models to reason about abstract structures and spaces, requiring sophisticated formal reasoning capabilities. The evaluation results are presented in Table 6. As shown, DeepSeek-Prover-V2-\n","\n","671B with CoT reasoning consistently outperforms all baselines, reinforcing the trends observed in other benchmark evaluations.\n","\n","## 4. Conclusion\n","\n","In this work, we propose a comprehensive pipeline for synthesizing cold-start reasoning data to advance formal theorem proving. Our data construction process is grounded in a recursive theorem-proving framework, wherein DeepSeek-V3 serves as a unified model for both subgoal decomposition and lemma formalization within the Lean 4 proof assistant. Our approach combines high-level proof sketches with formal steps, creating a sequence of manageable subgoals that can be efficiently solved using a smaller 7B model, significantly reducing computational requirements. The curriculum learning framework we developed uses these decomposed subgoals to generate increasingly difficult training tasks, creating a more effective learning progression. By pairing complete formal proofs with DeepSeek-V3's chain-of-thought reasoning, we established valuable cold-start reasoning data that bridges informal mathematical thinking with formal proof structures. The subsequent reinforcement learning stage substantially enhanced this connection, leading to significant improvements in formal theorem proving capabilities. The resulting model, DeepSeek-Prover-V2-671B, consistently outperforms all baselines across a range of benchmarks, spanning both high-school competition problems and undergraduatelevel mathematics. Our future work will focus on scaling this paradigm to an AlphaProof-like system with the ultimate aim of tackling IMO-level mathematical problems that represent the frontier of automated theorem proving challenges.\n","\n","## References\n","\n","- Z. Azerbayev, B. Piotrowski, H. Schoelkopf, E. W. Ayers, D. Radev, and J. Avigad. ProofNet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023.\n","- B. Barras, S. Boutin, C. Cornes, J. Courant, Y. Coscoy, D. Delahaye, D. de Rauglaudre, J.-C. Filliâtre, E. Giménez, H. Herbelin, et al. The Coq proof assistant reference manual. INRIA, version, 6(11):17-21, 1999.\n","- A. G. Barto and S. Mahadevan. Recent advances in hierarchical reinforcement learning. Discrete event dynamic systems, 13:341-379, 2003.\n","- DeepMind. AI achieves silver-medal standard solving international mathematical olympiad problems. https://deepmind.google/discover/blog/ai-solves-imo-problems-a t-silver-medal-level/ , 2024.\n","- DeepSeek-AI. Deepseek-v3 technical report, 2024. URL https://arxiv.org/abs/2412.194 37 .\n","- DeepSeek-AI. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL https://arxiv.org/abs/2501.12948 .\n","- K. Dong and T. Ma. STP: Self-play llm theorem provers with iterative conjecturing and proving. arXiv preprint arXiv:2502.00212, 2025.\n","- K. Dong, A. Mahankali, and T. Ma. Formal theorem proving by rewarding llms to decompose proofs hierarchically. arXiv preprint arXiv:2411.01829, 2024.\n","\n","| M. Eppe, C. Gumbsch, M. Kerzel, P. D. Nguyen, M. V. Butz, and S. Wermter. Intelligent problem- solving as integrated hierarchical reinforcement learning. Nature Machine Intelligence, 4(1): 11-20, 2022.                                                                                           |\n","|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt. Measuring mathematical problem solving with the MATHdataset. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.                      |\n","| A. Jaech, A. Kalai, A. Lerer, A. Richardson, A. El-Kishky, A. Low, A. Helyar, A. Madry, A. Beutel, A. Carney, et al. Openai o1 system card. arXiv preprint arXiv:2412.16720, 2024.                                                                                                                  |\n","| A. Q. Jiang, S. Welleck, J. P. Zhou, T. Lacroix, J. Liu, W. Li, M. Jamnik, G. Lample, and Y. Wu. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. In The Eleventh International Conference on Learning Representations, 2023.                                         |\n","| G. Lample, M.-A. Lachaux, T. Lavril, X. Martinet, A. Hayat, G. Ebner, A. Rodriguez, and T. Lacroix. Hypertree proof search for neural theorem proving. In Proceedings of the 36th International Conference on Neural Information Processing Systems, pages 26337-26349, 2022.                       |\n","| Y. Li, D. Du, L. Song, C. Li, W. Wang, T. Yang, and H. Mi. Hunyuanprover: A scalable data synthesis framework and guided tree search for automated theorem proving. arXiv preprint arXiv:2412.20735, 2024.                                                                                          |\n","| Y. Lin, S. Tang, B. Lyu, J. Wu, H. Lin, K. Yang, J. Li, M. Xia, D. Chen, S. Arora, et al. Goedel- Prover: A frontier model for open-source automated theorem proving. arXiv preprint arXiv:2502.07640, 2025.                                                                                        |\n","| J. Liu, X. Lin, J. Bayer, Y. Dillies, W. Jiang, X. Liang, R. Soletskyi, H. Wang, Y. Xie, B. Xiong, et al. CombiBench: Benchmarking llm capability for combinatorial mathematics. https: //moonshotai.github.io/CombiBench/ , 2025.                                                                  |\n","| L. d. Moura and S. Ullrich. The Lean 4 theorem prover and programming language. In Automated Deduction-CADE 28: 28th International Conference on Automated Deduction, Virtual Event, July 12-15, 2021, Proceedings 28, pages 625-635. Springer, 2021.                                               |\n","| O. Nachum, S. S. Gu, H. Lee, and S. Levine. Data-efficient hierarchical reinforcement learning. Advances in neural information processing systems, 31, 2018.                                                                                                                                        |\n","| L. C. Paulson. Isabelle a Generic Theorem Prover. Springer Verlag, 1994.                                                                                                                                                                                                                            |\n","| S. Polu and I. Sutskever. Generative language modeling for automated theorem proving. arXiv preprint arXiv:2009.03393, 2020.                                                                                                                                                                        |\n","| J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.                                                                                                                                                     |\n","| Z. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y. Li, Y. Wu, and D. Guo. DeepSeekMath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.                                                                                            |\n","| G. Tsoukalas, J. Lee, J. Jennings, J. Xin, M. Ding, M. Jennings, A. Thakur, and S. Chaudhuri. PutnamBench: Evaluating neural theorem-provers on the putnam mathematical competi- tion. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024. |\n","\n","| H. Wang, H. Xin, Z. Liu, W. Li, Y. Huang, J. Lu, Y. Zhicheng, J. Tang, J. Yin, Z. Li, et al. Prov- ing theorems recursively. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024a.                                              |\n","|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| H. Wang, H. Xin, C. Zheng, Z. Liu, Q. Cao, Y. Huang, J. Xiong, H. Shi, E. Xie, J. Yin, et al. Lego-prover: Neural theorem proving with growing libraries. In The Twelfth International Conference on Learning Representations, 2024b.                             |\n","| H. Wang, M. Unsal, X. Lin, M. Baksys, J. Liu, M. D. Santos, F. Sung, M. Vinyes, Z. Ying, Z. Zhu, et al. Kimina-Prover Preview: Towards large formal reasoning models with reinforcement learning. arXiv preprint arXiv:2504.11354, 2025.                          |\n","| Z. Wu, S. Huang, Z. Zhou, H. Ying, J. Wang, D. Lin, and K. Chen. Internlm2. 5-stepprover: Advancing automated theorem proving via expert iteration on large-scale lean problems. arXiv preprint arXiv:2410.15700, 2024.                                           |\n","| H. Xin, D. Guo, Z. Shao, Z. Ren, Q. Zhu, B. Liu, C. Ruan, W. Li, and X. Liang. DeepSeek- Prover: Advancing theorem proving in llms through large-scale synthetic data. arXiv preprint arXiv:2405.14333, 2024a.                                                    |\n","| H. Xin, Z. Ren, J. Song, Z. Shao, W. Zhao, H. Wang, B. Liu, L. Zhang, X. Lu, Q. Du, et al. DeepSeek-Prover-V1.5: Harnessing proof assistant feedback for reinforcement learning and monte-carlo tree search. arXiv preprint arXiv:2408.08152, 2024b.              |\n","| R. Xin, C. Xi, J. Yang, F. Chen, H. Wu, X. Xiao, Y. Sun, S. Zheng, and K. Shen. BFS-Prover: Scalable best-first tree search for llm-based automatic theorem proving. arXiv preprint arXiv:2502.03438, 2025.                                                       |\n","| K. Yang, G. Poesia, J. He, W. Li, K. Lauter, S. Chaudhuri, and D. Song. Formal mathematical reasoning: Anew frontier in AI. arXiv preprint arXiv:2412.16075, 2024.                                                                                                |\n","| H. Ying, Z. Wu, Y. Geng, J. Wang, D. Lin, and K. Chen. Lean workbook: A large-scale lean problem set formalized from natural language math problems. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024. |\n","| J. Zhang, Q. Wang, X. Ji, Y. Liu, Y. Yue, F. Zhang, D. Zhang, G. Zhou, and K. Gai. Leanabell-prover: Posttraining scaling in formal reasoning. arXiv preprint arXiv:2504.06122, 2025.                                                                             |\n","| X. Zhao, W. Li, and L. Kong. Decomposing the enigma: Subgoal-based demonstration learning for formal theorem proving. arXiv preprint arXiv:2305.16366, 2023.                                                                                                      |\n","| X. Zhao, L. Zheng, H. Bo, C. Hu, U. Thakker, and L. Kong. Subgoalxl: Subgoal-based expert learning for theorem proving. arXiv preprint arXiv:2408.11172, 2024.                                                                                                    |\n","| C. Zheng, H. Wang, E. Xie, Z. Liu, J. Sun, H. Xin, J. Shen, Z. Li, and Y. Li. Lyra: Orchestrating dual correction in automated theorem proving. Transactions on Machine Learning Research, 2024.                                                                  |\n","| K. Zheng, J. M. Han, and S. Polu. miniF2F: a cross-system benchmark for formal olympiad-level mathematics. In International Conference on Learning Representations, 2022.                                                                                         |\n","\n","## A. Examples of Non-CoT and CoT Prompting for Proof Generation\n","\n","## A.1. Non-CoT Generation of DeepSeek-Prover-V2\n","\n","Input :\n","\n","```\n","Complete the following Lean 4 code: '''lean4 import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat /--Prove that cos 𝜋 7 -cos 2 𝜋 7 + cos 3 𝜋 7 = 1 2 .-/ theorem imo_1963_p5 : Real.cos (Real.pi / 7) - Real.cos (2 * Real.pi / 7) + Real.cos (3 * Real.pi / 7) = 1 / 2 := by sorry '''\n","```\n","\n","Output :\n","\n","```\n","''' lean4 import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat /-- Prove that cos 𝜋 7 -cos 2 𝜋 7 + cos 3 𝜋 7 = 1 2 .-/ theorem imo_1963_p5 : Real cos . ( Real pi . / 7) Real cos . (2 * Real pi . / 7) + Real cos . (3 * Real pi . / 7) = 1 / 2 := by have h 1 : Real cos . ( Real pi . / 7) > 0 := Real cos_pos_of_mem_Ioo . ⟨ by linarith [ Real pi_gt_three . ], by linarith [ Real pi_gt_three . ] ⟩ have h 2 : Real cos . (2 * Real pi . / 7) = Real cos . (2 * Real pi . / 7) := rfl have h 3 : Real cos . (3 * Real pi . / 7) = Real cos . (3 * Real pi . / 7) := rfl have h 4 : Real cos . ( Real pi . / 7) Real cos . (2 * Real pi . / 7) + Real cos . (3 * Real pi . / 7) = 1 / 2 := by -- Use the identity for the sum of cosines with specific angles to simplify the expression have h 5 : Real cos . (2 * Real pi . / 7) = Real cos . (2 * ( Real pi . / 7)) := by ring have h 6 : Real cos . (3 * Real pi . / 7) = Real cos . (3 * ( Real pi . / 7)) := by ring rw [ h 5 , h 6 ] have h 7 : Real cos . (2 * ( Real pi . / 7)) = 2 * Real cos . ( Real pi . / 7) ^ 2 - 1 := by have h 71 : Real cos . (2 * ( Real pi . / 7)) = 2 * Real cos . ( Real pi . / 7) ^ 2 - 1 := by rw [ Real cos_two_mul . ] <;> ring_nf <;> nlinarith [ Real cos_sq_add_sin_sq . ( Real pi . / 7)] rw [ h 71 ] have h 8 : Real cos . (3 * ( Real pi . / 7)) = 4 * Real cos . ( Real pi . / 7) ^ 3 - 3 * Real cos . ( Real pi . / 7) := by have h 81 : Real cos . (3 * ( Real pi . / 7)) = 4 * Real cos . ( Real pi . / 7) ^ 3 - 3 * Real cos . ( Real pi . / 7) := by rw [ show Real cos . (3 * ( Real pi . / 7)) = Real cos . (3 * ( Real pi . / 7)) by rfl ] have h 82 : Real cos . (3 * ( Real pi . / 7)) = 4 * Real cos . ( Real pi . / 7) ^ 3 - 3 * Real cos . ( Real pi . / 7) := by rw [ show Real cos . (3 * ( Real pi . / 7)) = Real cos . (3 * ( Real pi . / 7)) by rfl ] -- Use the triple angle identity for cosine have h 83 : Real cos . (3 * ( Real pi . / 7)) = 4 * Real cos . ( Real pi . / 7) ^ 3 - 3 * Real cos . ( Real pi . / 7) := by rw [ Real cos_three_mul . ] <;> ring_nf\n","```\n","\n","```\n","<;> nlinarith [ Real cos_sq_add_sin_sq . ( Real pi . / 7), Real sin_le_one . ( Real pi . / 7), Real cos_le_one . ( Real pi . / 7)] rw [ h 83 ] rw [ h 82 ] rw [ h 81 ] rw [ h 7 , h 8 ] -- Simplify the expression using the derived identities have h 9 : Real cos . ( Real pi . / 7) > 0 := h 1 have h 10 : Real cos . ( Real pi . / 7) ≠ 0 := by linarith -- Use the quadratic equation to solve for the sum of cosines have h 11 : Real cos . ( Real pi . / 7) = Real cos . ( Real pi . / 7) := rfl have h 12 : 8 * Real cos . ( Real pi . / 7) ^ 3 - 4 * Real cos . ( Real pi . / 7) ^ 2 - 4 * Real cos . ( Real pi . / 7) + 1 = 0 := by -- Use the identity to form a polynomial equation and solve it have h 13 : Real cos . ( Real pi . / 7) > 0 := h 1 have h 14 : Real cos . ( Real pi . / 7) ≠ 0 := by linarith have h 15 : Real cos . ( Real pi . / 7) = Real cos . ( Real pi . / 7) := rfl -- Use the polynomial equation to find the sum of cosines have h 16 : Real cos . ( Real pi . / 7) ⩾ 0 := by linarith -- Use the identity to form a polynomial equation and solve it have h 17 : Real sin . ( Real pi . / 7) > 0 := by apply Real sin_pos_of_pos_of_lt_pi . <;> linarith [ Real pi_gt_three . ] have h 18 : Real sin . (3 * ( Real pi . / 7)) > 0 := by apply Real sin_pos_of_pos_of_lt_pi . <;> ( try ring_nf at * <;> nlinarith [ Real pi_gt_three . ]) <;> ( try ring_nf ) <;> ( try nlinarith [ Real pi_gt_three . ]) have h 19 : Real sin . (3 * ( Real pi . / 7)) = 3 * Real sin . ( Real pi . / 7) - 4 * Real sin . ( Real pi . / 7) ^ 3 := by have h 191 : Real sin . (3 * ( Real pi . / 7)) = 3 * Real sin . ( Real pi . / 7) - 4 * Real sin . ( Real pi . / 7) ^ 3 := by rw [ Real sin_three_mul . ] <;> ring_nf <;> nlinarith [ Real cos_sq_add_sin_sq . ( Real pi . / 7), Real sin_le_one . ( Real pi . / 7), Real cos_le_one . ( Real pi . / 7)] rw [ h 191 ] have h 20 : Real sin . (2 * ( Real pi . / 7)) = 2 * Real sin . ( Real pi . / 7) * Real cos . ( Real pi . / 7) := by have h 201 : Real sin . (2 * ( Real pi . / 7)) = 2 * Real sin . ( Real pi . / 7) * Real cos . ( Real pi . / 7) := by rw [ Real sin_two_mul . ] <;> ring_nf <;> nlinarith [ Real cos_sq_add_sin_sq . ( Real pi . / 7), Real sin_le_one . ( Real pi . / 7), Real cos_le_one . ( Real pi . / 7)] rw [ h 201 ] have h 21 : Real sin . (3 * ( Real pi . / 7)) = Real sin . ( Real pi . - 4 * ( Real pi . / 7)) := by have h 211 : 3 * ( Real pi . / 7) = Real pi . - 4 * ( Real pi . / 7) := by ring rw [ h 211 ] have h 22 : Real sin . ( Real pi . - 4 * ( Real pi . / 7)) = Real sin . (4 * ( Real pi . / 7)) := by rw [ Real sin_pi_sub . ] have h 23 : Real sin . (4 * ( Real pi . / 7)) = 2 * Real sin . (2 * ( Real pi . / 7)) * Real cos . (2 * ( Real pi . / 7)) := by have h 231 : Real sin . (4 * ( Real pi . / 7)) = 2 * Real sin . (2 * ( Real pi . / 7)) * Real cos . (2 * ( Real pi . / 7)) := by have h 232 : Real sin . (4 * ( Real pi . / 7)) = Real sin . (2 * (2 * ( Real pi . / 7))) := by ring rw [ h 232 ] have h 233 : Real sin . (2 * (2 * ( Real pi . / 7))) = 2 * Real sin . (2 * ( Real pi . / 7)) * Real cos . (2 * ( Real pi . / 7)) := by rw [ Real sin_two_mul . ] <;> ring_nf rw [ h 233 ] rw [ h 231 ] have h 24 : Real sin . (2 * ( Real pi . / 7)) > 0 := by apply Real sin_pos_of_pos_of_lt_pi .\n","```\n","\n","```\n","<;> ( try ring_nf at * <;> nlinarith [ Real pi_gt_three . ]) <;> ( try ring_nf ) <;> ( try nlinarith [ Real pi_gt_three . ]) have h 25 : Real cos . (2 * ( Real pi . / 7)) > 0 := by have h 251 : Real cos . (2 * ( Real pi . / 7)) > 0 := by apply Real cos_pos_of_mem_Ioo . <;> constructor <;> ( try ring_nf at * <;> nlinarith [ Real pi_gt_three . ]) <;> ( try ring_nf ) <;> ( try nlinarith [ Real pi_gt_three . ]) linarith have h 26 : Real sin . (3 * ( Real pi . / 7)) > 0 := h 18 have h 27 : Real sin . ( Real pi . / 7) > 0 := h 17 have h 28 : Real sin . (2 * ( Real pi . / 7)) > 0 := h 24 have h 29 : Real cos . (2 * ( Real pi . / 7)) > 0 := h 25 -- Use the polynomial equation to find the sum of cosines nlinarith [ Real sin_sq_add_cos_sq . ( Real pi . / 7), Real sin_sq_add_cos_sq . (2 * ( Real pi . / 7)), Real sin_sq_add_cos_sq . (3 * ( Real pi . / 7)), Real sin_le_one . ( Real pi . / 7), Real sin_le_one . (2 * ( Real pi . / 7)), Real sin_le_one . (3 * ( Real pi . / 7)), Real cos_le_one . ( Real pi . / 7), Real cos_le_one . (2 * ( Real pi . / 7)), Real cos_le_one . (3 * ( Real pi . / 7))] -- Use the polynomial equation to find the sum of cosines nlinarith [ Real cos_le_one . ( Real pi . / 7), Real cos_le_one . (2 * ( Real pi . / 7)), Real cos_le_one . (3 * ( Real pi . / 7))] -- Use the polynomial equation to find the sum of cosines linarith '''\n","```\n","\n","## A.2. CoT Generation Strategy of DeepSeek-Prover-V2\n","\n","Input :\n","\n","```\n","Complete the following Lean 4 code: '''lean4 import Mathlib import Aesop set_option maxHeartbeats 0 open BigOperators Real Nat Topology Rat /--Let 𝑝 𝑞 𝑟 , , be integers with 1 < 𝑝 < 𝑞 < 𝑟 . Show that if ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) divides 𝑝𝑞𝑟 -1 , then ( 𝑝 𝑞 𝑟 , , ) = ( 2, 4, 8 ) or ( 𝑝 𝑞 𝑟 , , ) = ( 3, 5, 15 ) .-/ theorem imo_1992_p1 (p q r : Z ) (h 0 : 1 < p ∧ p < q ∧ q < r) (h 1 : (p - 1) * (q - 1) * (r -1) | p * q * r -1) : (p, q, r) = (2, 4, 8) ∨ (p, q, r) = (3, 5, 15) := by sorry ''' Before producing the Lean 4 code to formally prove the given theorem, provide a detailed proof plan outlining the main proof steps and strategies. The plan should highlight key ideas, intermediate lemmas, and proof structures that will guide the construction of the final formal proof.\n","```\n","\n","To enhance clarity, model outputs are reformulated using inline LaTeX expressions.\n","\n","Output :\n","\n","## ### Detailed Proof and Analysis\n","\n","We are given integers 𝑝 𝑞 𝑟 , , such that 1 &lt; 𝑝 &lt; 𝑞 &lt; 𝑟 , and ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) divides 𝑝𝑞𝑟 -1. We need to prove that ( 𝑝 𝑞 𝑟 , , ) is either ( 2, 4, 8 ) or ( 3, 5, 15 ) . #### Step 1: Understand the divisibility condition The condition ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) | 𝑝𝑞𝑟 -1 can be rewritten as : 𝑝𝑞𝑟 -1 = 𝑘 · ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) for some positive integer 𝑘 , since 𝑝 𝑞 𝑟 &gt; , , 1, so ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) &gt; 0, and 𝑝𝑞𝑟 -1 &gt; 0. #### Step 2: Derive an upper bound for 𝑘 We can write : 𝑝𝑞𝑟 -1 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) = 𝑘 We claim that 𝑘 &lt; 4. To prove this observe that , : 𝑝𝑞𝑟 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) = GLYPH&lt;16&gt; 1 + 1 𝑝 -1 GLYPH&lt;17&gt; GLYPH&lt;16&gt; 1 + 1 𝑞 -1 GLYPH&lt;17&gt; GLYPH&lt;16&gt; 1 + 1 𝑟 -1 GLYPH&lt;17&gt; Since 𝑝 ⩾ 2, 𝑞 ⩾ 3, 𝑟 ⩾ 4, we have : 1 + 1 𝑝 -1 ⩽ 2, 1 + 1 𝑞 -1 ⩽ 3 2 , 1 + 1 𝑟 -1 ⩽ 4 3 so : 𝑝𝑞𝑟 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) ⩽ 2 · 3 2 · 4 3 = 4 Thus : 𝑘 = 𝑝𝑞𝑟 -1 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) &lt; 𝑝𝑞𝑟 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) ⩽ 4 so 𝑘 ⩽ 3. But we can do better The function . 𝑓 ( 𝑝 𝑞 𝑟 , , ) = 𝑝𝑞𝑟 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) is decreasing in 𝑝 𝑞 𝑟 , , , so its maximum in 𝑝 ⩾ 2, 𝑞 ⩾ 𝑝 + 1, 𝑟 ⩾ 𝑞 + 1 is achieved at ( 2, 3, 4 ) , where 𝑓 ( 2, 3, 4 ) = 24 1 2 3 · · = 4. At ( 2, 3, 5 ) , it is 30 1 2 4 · · = 3.75 &lt; 4, etc . But the precise calculation is not needed Since . 𝑝 ⩾ 2, 𝑞 ⩾ 3, 𝑟 ⩾ 4, 1 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) ⩽ 1 6 , while 𝑝𝑞𝑟 ⩾ 24, so : 𝑘 = 𝑝𝑞𝑟 -1 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) &lt; 𝑝𝑞𝑟 ( 𝑝 - )( 1 𝑞 - )( -1 𝑟 1 ) ⩽ 4 and the bound 𝑘 &lt; 4 follows Since . 𝑘 is an integer , 𝑘 ∈ { 1, 2, 3 } . However we can tighten this further The condition , . 𝑘 ⩾ 4 would require ( 𝑝 𝑞 𝑟 , , ) = ( 2, 3, 4 ) , but 𝑝𝑞𝑟 -1 = 23 and ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) = 6, which does not divide So we must have . 𝑘 &lt; 4. Alternatively we can note that for , 𝑝 ⩾ 2, 𝑞 ⩾ 3, 𝑟 ⩾ 4, the product ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) is at least 6, and 𝑝𝑞𝑟 -1 &lt; 𝑝𝑞𝑟 , so 𝑘 ⩽ 3. #### Step 3: Consider possible values of 𝑘 The key is to consider 𝑘 = 1, 2, 3 and solve for ( 𝑝 𝑞 𝑟 , , ) . ** Case 𝑘 = 1:** 𝑝𝑞𝑟 -1 = ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) Expand the right side : 𝑝𝑞𝑟 -𝑝𝑞 -𝑝𝑟 -𝑞𝑟 + 𝑝 + 𝑞 + 𝑟 -1 = 𝑝𝑞𝑟 -1 Simplify to : -𝑝𝑞 -𝑝𝑟 -𝑞𝑟 + 𝑝 + 𝑞 + 𝑟 = 0 or : 𝑝𝑞 + 𝑝𝑟 + 𝑞𝑟 = 𝑝 + 𝑞 + 𝑟 Since 𝑝 𝑞 𝑟 , , ⩾ 2, we have 𝑝𝑞 + 𝑝𝑟 + 𝑞𝑟 ⩾ 4 𝑝 + 4 𝑞 + 4 , 𝑟 which is much larger than 𝑝 + 𝑞 + 𝑟 , so no solutions exist .\n","\n","```\n","** Case 𝑘 = 2:** 𝑝𝑞𝑟 -1 = 2 ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) Expand and simplify : 𝑝𝑞𝑟 -1 = 2 ( 𝑝𝑞𝑟 -𝑝𝑞 -𝑝𝑟 -𝑞𝑟 + 𝑝 + 𝑞 + 𝑟 -1 ) 𝑝𝑞𝑟 -1 = 2 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -2 -𝑝𝑞𝑟 + 2 𝑝𝑞 + 2 𝑝𝑟 + 2 𝑞𝑟 -2 𝑝 -2 𝑞 -2 𝑟 + 1 = 0\n","```\n","\n","```\n","Multiply by -1: 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -1 = 0 Factor : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) = 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 4 𝑝 + 4 𝑞 + 4 𝑟 -8 But : 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -1 = 0 Thus : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) = ( 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -1 ) - (-2 𝑝 -2 𝑞 -2 𝑟 + 7 ) Wait no It is easier to write , . : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) = 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 4 𝑝 + 4 𝑞 + 4 𝑟 -8 Then : 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -1 = 0 Subtract : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) - ( 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -1 ) = 2 𝑝 + 2 𝑞 + 2 𝑟 -7 But from above : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) = 2 𝑝 + 2 𝑞 + 2 𝑟 -7 Since 𝑝 ⩾ 2, the left is ⩾ 0, so 2 𝑝 + 2 𝑞 + 2 𝑟 -7 ⩾ 0. But now set , 𝑝 = 2. Then the original equation is : 2 𝑞𝑟 -1 = 2 1 ( )( 𝑞 -1 )( 𝑟 -1 ) = 2 ( 𝑞𝑟 -𝑞 -𝑟 + 1 ) Simplify : 2 𝑞𝑟 -1 = 2 𝑞𝑟 -2 𝑞 -2 𝑟 + 2 -1 = -2 𝑞 -2 𝑟 + 2 2 𝑞 + 2 𝑟 = 3 But 𝑞 ⩾ 3 ( since 𝑝 = 2, 𝑞 > 𝑝 ), so 2 𝑞 + 2 𝑟 ⩾ 6, contradiction Hence no solution with . 𝑝 = 2. Similarly set , 𝑝 = 3: 3 𝑞𝑟 -1 = 2 2 ( )( 𝑞 -1 )( 𝑟 -1 ) 3 𝑞𝑟 -1 = 4 ( 𝑞𝑟 -𝑞 -𝑟 + 1 ) 3 𝑞𝑟 -1 = 4 𝑞𝑟 -4 𝑞 -4 𝑟 + 4 -𝑞𝑟 + 4 𝑞 + 4 𝑟 -5 = 0 𝑞𝑟 -4 𝑞 -4 𝑟 + 5 = 0 Add 11: 𝑞𝑟 -4 𝑞 -4 𝑟 + 16 = 11 Factor : ( 𝑞 -4 )( 𝑟 -4 ) = 11 Since 𝑞 > 𝑝 = 3, 𝑞 ⩾ 4, and 𝑟 > 𝑞 , possible factorings are : -𝑞 -4 = 1, 𝑟 -4 = 11: 𝑞 = 5, 𝑟 = 15 -𝑞 -4 = 11, 𝑟 -4 = 1: But then 𝑞 = 15, 𝑟 = 5, but 𝑟 > 𝑞 , invalid . Thus the only solution is , ( 𝑝 𝑞 𝑟 , , ) = ( 3, 5, 15 ) . Next set , 𝑝 = 4. The original equation is : 4 𝑞𝑟 -1 = 2 3 ( )( 𝑞 -1 )( 𝑟 -1 ) = 6 ( 𝑞𝑟 -𝑞 -𝑟 + 1 ) 4 𝑞𝑟 -1 = 6 𝑞𝑟 -6 𝑞 -6 𝑟 + 6 -2 𝑞𝑟 + 6 𝑞 + 6 𝑟 -7 = 0 Multiply by 2: -4 𝑞𝑟 + 12 𝑞 + 12 𝑟 -14 = 0 Factor : ( 2 𝑞 -3 )( 2 𝑟 -3 ) = 23 Since 𝑞 ⩾ 5, 𝑟 ⩾ 6, ( 2 𝑞 -3 )( 2 𝑟 -3 ) ⩾ 7 · 9 = 63 > 23, no solutions . For 𝑝 ⩾ 4, the term ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) dominates 2 𝑝 + 2 𝑞 + 2 𝑟 -7, so no solutions will exist Formally . , since 𝑞 ⩾ 𝑝 + 1 ⩾ 5, 𝑟 ⩾ 𝑞 + 1 ⩾ 6, we have : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) ⩾ ( 4 -2 )( 5 -2 )( 6 -2 ) = 24 while 2 𝑝 + 2 𝑞 + 2 𝑟 -7 ⩽ 2 ( 𝑟 -2 ) + 2 ( 𝑟 -1 ) + 2 𝑟 -7 = 6 𝑟 -13, but no let s instead note that , ' : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) ⩾ ( 𝑝 -2 )(( 𝑝 + 1 ) -2 )(( 𝑝 + 2 ) -2 ) = ( 𝑝 -2 )( 𝑝 -1 )( 𝑝 ) and 2 𝑝 + 2 𝑞 + 2 𝑟 -7 < 6 . 𝑟 But 𝑝 ⩾ 4, ( 𝑝 -2 )( 𝑝 -1 )( 𝑝 ) ⩾ 24, 𝑟 ⩾ 𝑝 + 2 ⩾ 6, but this is not directly leading to a contradiction . Alternatively just note that , 𝑞 ⩾ 𝑝 + 1, 𝑟 ⩾ 𝑝 + 2, so : ( 𝑝 -2 )( 𝑞 -2 )( 𝑟 -2 ) ⩾ ( 𝑝 -2 )( 𝑝 -1 )( 𝑝 ) ⩾ ( 4 -2 )( 4 -1 )( 4 ) = 24\n","```\n","\n","```\n","and 2 𝑝 + 2 𝑞 + 2 𝑟 -7 ⩽ 2 𝑝 + 2 ( 𝑝 + 1 ) + 2 ( 𝑝 + 2 ) -7 = 6 𝑝 -1. But 6 𝑝 -1 < ( 𝑝 -2 )( 𝑝 -1 )( 𝑝 ) for 𝑝 ⩾ 4, since 𝑝 = 4 gives 23 < 24, 𝑝 = 5 gives 29 < 60, etc Thus no solutions exist for . 𝑝 ⩾ 4. But we have already found ( 3, 5, 15 ) , and need to consider other 𝑘 . Wait we found that , 𝑘 = 2 yields only ( 3, 5, 15 ) . Now consider , 𝑘 = 3. ** Case 𝑘 = 3:** The equation is : 𝑝𝑞𝑟 -1 = 3 ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 ) Expand : 𝑝𝑞𝑟 -1 = 3 ( 𝑝𝑞𝑟 -𝑝𝑞 -𝑝𝑟 -𝑞𝑟 + 𝑝 + 𝑞 + 𝑟 -1 ) 𝑝𝑞𝑟 -1 = 3 𝑝𝑞𝑟 -3 𝑝𝑞 -3 𝑝𝑟 -3 𝑞𝑟 + 3 𝑝 + 3 𝑞 + 3 𝑟 -3 -2 𝑝𝑞𝑟 + 3 𝑝𝑞 + 3 𝑝𝑟 + 3 𝑞𝑟 -3 𝑝 -3 𝑞 -3 𝑟 + 2 = 0 Multiply by -1: 2 𝑝𝑞𝑟 -3 𝑝𝑞 -3 𝑝𝑟 -3 𝑞𝑟 + 3 𝑝 + 3 𝑞 + 3 𝑟 -2 = 0 As before look for small , 𝑝 . Set 𝑝 = 2: 4 𝑞𝑟 -6 𝑞 -6 𝑟 + 6 + 3 𝑞 + 3 𝑟 -2 = 0 Simplify : 4 𝑞𝑟 -3 𝑞 -3 𝑟 + 4 = 0 Factor : ( 4 𝑞 -3 )( 𝑟 ) -3 𝑞 + 4 = 0 Not obvious but solve , : 4 𝑞𝑟 -3 𝑞 -3 𝑟 + 4 = 0 4 𝑞𝑟 -3 𝑞 -3 𝑟 = -4 Not possible since 𝑞 ⩾ 3, 𝑟 ⩾ 4, so 4 𝑞𝑟 -3 𝑞 -3 𝑟 ⩾ 4 · 3 · 4 -3 · 3 -3 · 4 = 48 -9 -12 = 27 > -4. Wait no contradiction Hence no solution with , , . 𝑝 = 2. Wait but we need to revisit the case when , 𝑝 = 2. The correct equation is : 2 𝑞𝑟 -1 = 3 1 ( )( 𝑞 -1 )( 𝑟 -1 ) = 3 ( 𝑞𝑟 -𝑞 -𝑟 + 1 ) Thus : 2 𝑞𝑟 -1 = 3 𝑞𝑟 -3 𝑞 -3 𝑟 + 3 -𝑞𝑟 + 3 𝑞 + 3 𝑟 -4 = 0 Multiply by -1: 𝑞𝑟 -3 𝑞 -3 𝑟 + 4 = 0 Add 5: 𝑞𝑟 -3 𝑞 -3 𝑟 + 9 = 5 Factor : ( 𝑞 -3 )( 𝑟 -3 ) = 5 Since 𝑞 ⩾ 3, 𝑟 ⩾ 4, possible pairs are : -𝑞 -3 = 1, 𝑟 -3 = 5: 𝑞 = 4, 𝑟 = 8 -𝑞 -3 = 5, 𝑟 -3 = 1: 𝑞 = 8, 𝑟 = 4, invalid as 𝑟 > 𝑞 . Thus the only solution is , ( 2, 4, 8 ) . Set 𝑝 = 3: 3 𝑞𝑟 -1 = 3 2 ( )( 𝑞 -1 )( 𝑟 -1 ) 3 𝑞𝑟 -1 = 6 ( 𝑞𝑟 -𝑞 -𝑟 + 1 ) 3 𝑞𝑟 -1 = 6 𝑞𝑟 -6 𝑞 -6 𝑟 + 6 -3 𝑞𝑟 + 6 𝑞 + 6 𝑟 -7 = 0 3 𝑞𝑟 -6 𝑞 -6 𝑟 + 7 = 0 Multiply by 4: 12 𝑞𝑟 -24 𝑞 -24 𝑟 + 28 = 0 Add 1: 12 𝑞𝑟 -24 𝑞 -24 𝑟 + 49 = 1 Factor : ( 3 𝑞 -6 )( 4 𝑟 -8 ) = -47 But 𝑞 ⩾ 4, 𝑟 ⩾ 5, so ( 3 𝑞 -6 ) ⩾ 6, ( 4 𝑟 -8 ) ⩾ 12, so left side is ⩾ 72, which cannot be -47. Thus no solution here .\n","```\n","\n","```\n","Set 𝑝 = 4: 4 𝑞𝑟 -1 = 3 3 ( )( 𝑞 -1 )( 𝑟 -1 ) 4 𝑞𝑟 -1 = 9 𝑞𝑟 -9 𝑞 -9 𝑟 + 9 -5 𝑞𝑟 + 9 𝑞 + 9 𝑟 -10 = 0 Multiply by 5: -25 𝑞𝑟 + 45 𝑞 + 45 𝑟 -50 = 0 Factor : ( 5 𝑞 -9 )( 5 𝑟 -9 ) = 31 Since 𝑞 ⩾ 5, 𝑟 ⩾ 6, ( 5 𝑞 -9 ) ⩾ 16, ( 5 𝑟 -9 ) ⩾ 21, so left side is ⩾ 16 · 21 = 336 > 31. Thus no solution here . Similarly for larger , 𝑝 ⩾ 4, no solutions exist because the term , 𝑝𝑞𝑟 dominates . #### Step 4: Conclusion The only triples ( 𝑝 𝑞 𝑟 , , ) satisfying all conditions are ( 2, 4, 8 ) and ( 3, 5, 15 ) . ### Step -by -Step Abstract Plan 1. ** Understand the Divison Condition **: -Rewrite the divisibility condition as 𝑝𝑞𝑟 -1 = 𝑘 · ( 𝑝 -1 )( 𝑞 -1 )( 𝑟 -1 . ) -Note that 𝑘 is a positive integer since all terms are positive . 2. ** Derive an Upper Bound for 𝑘 **: -Use inequalities to show that 𝑘 < 4, i e . ., 𝑘 ⩽ 3. -Alternatively note that for , 𝑝 𝑞 𝑟 , , in the given range , 𝑘 ⩽ 3 is natural as larger , 𝑘 would make the right side too large . 3. ** Case 𝑘 = 1**: -Derive the equation 𝑝𝑞 + 𝑝𝑟 + 𝑞𝑟 = 𝑝 + 𝑞 + 𝑟 . -This has no solutions since 𝑝 𝑞 𝑟 , , ⩾ 2, making the left side much larger than the right . 4. ** Case 𝑘 = 2**: -Derive the equation 𝑝𝑞𝑟 -2 𝑝𝑞 -2 𝑝𝑟 -2 𝑞𝑟 + 2 𝑝 + 2 𝑞 + 2 𝑟 -1 = 0. -For 𝑝 = 2, no solution . -For 𝑝 = 3, solve to get ( 𝑝 𝑞 𝑟 , , ) = ( 3, 5, 15 ) . -For 𝑝 ⩾ 4, no solutions exist . 5. ** Case 𝑘 = 3**: -Derive the equation 2 𝑝𝑞𝑟 -3 𝑝𝑞 -3 𝑝𝑟 -3 𝑞𝑟 + 3 𝑝 + 3 𝑞 + 3 𝑟 -2 = 0. -For 𝑝 = 2, solve to get ( 𝑝 𝑞 𝑟 , , ) = ( 2, 4, 8 ) . -For 𝑝 ⩾ 3, no solutions exist . 6. ** Conclusion **: -The only valid triples are ( 2, 4, 8 ) and ( 3, 5, 15 ) . ### Lean 4 Proof with have Statements ' ' ''' lean4 theorem imo_1992_p1 ( p q r : Z ) ( h 0 : 1 < p ∧ p < q ∧ q < r ) ( h 1 : ( p - 1) * ( q - 1) * ( r - 1) | p * q * r - 1) : ( p q r , , ) = (2, 4, 8) ∨ ( p q r , , ) = (3, 5, 15) := by have h 2 : p ⩾ 2 := by sorry have h 3 : q ⩾ 3 := by sorry have h 4 : r ⩾ 4 := by sorry have h 5 : ( p q r , , ) = (2, 4, 8) ∨ ( p q r , , ) = (3, 5, 15) := by sorry sorry ''' ### Complete Lean 4 Proof ''' lean4\n","```\n","\n","```\n","theorem imo_1992_p1 ( p q r : Z ) ( h 0 : 1 < p ∧ p < q ∧ q < r ) ( h 1 : ( p - 1) * ( q - 1) * ( r - 1) | p * q * r - 1) : ( p q r , , ) = (2, 4, 8) ∨ ( p q r , , ) = (3, 5, 15) := by have h 2 : p ⩾ 2 := by linarith [ h 0 .1] have h 3 : q ⩾ 3 := by by_contra h have h 4 : q ⩽ 2 := by linarith have h 5 : q ⩾ 2 := by linarith [ h 0 .2.1] have h 6 : q = 2 := by linarith have h 7 : p < 2 := by linarith [ h 0 .2.1] have h 8 : p ⩾ 2 := by linarith [ h 0 .1] linarith have h 4 : r ⩾ 4 := by by_contra h have h 5 : r ⩽ 3 := by linarith have h 6 : r ⩾ 3 := by linarith [ h 0 .2.2] have h 7 : r = 3 := by linarith have h 8 : q < 3 := by linarith [ h 0 .2.2] have h 9 : q ⩾ 3 := by linarith [ h 3 ] linarith have h 5 : ( p q r , , ) = (2, 4, 8) ∨ ( p q r , , ) = (3, 5, 15) := by have h 6 : ( p - 1 : Z ) > 0 := by linarith have h 7 : ( q - 1 : Z ) > 0 := by linarith have h 8 : ( r - 1 : Z ) > 0 := by linarith have h 9 : ( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z ) > 0 := by positivity have h 10 : ∃ ( k : Z ), ( p * q * r - 1 : Z ) = k * (( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z )) := by obtain ⟨ k hk , ⟩ := h 1 refine ' ⟨ k _ , ⟩ linarith obtain ⟨ k hk , ⟩ := h 10 have h 11 : k > 0 := by by_contra h 11 have h 12 : k ⩽ 0 := by linarith have h 13 : ( p * q * r - 1 : Z ) ⩽ 0 := by nlinarith [ mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 3 ), mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 4 ), mul_nonneg ( sub_nonneg mpr h . 3 ) ( sub_nonneg mpr h . 4 )] have h 14 : ( p * q * r : Z ) ⩽ 1 := by linarith have h 15 : ( p : Z ) ⩾ 2 := by linarith have h 16 : ( q : Z ) ⩾ 3 := by linarith have h 17 : ( r : Z ) ⩾ 4 := by linarith have h 18 : ( p * q * r : Z ) ⩾ 2 * 3 * 4 := by have h 19 : ( p : Z ) * q ⩾ 2 * 3 := by nlinarith nlinarith linarith have h 12 : k ⩽ 3 := by by_contra h 12 have h 13 : k ⩾ 4 := by linarith have h 14 : ( p - 1 : Z ) ⩾ 1 := by linarith have h 15 : ( q - 1 : Z ) ⩾ 2 := by linarith have h 16 : ( r - 1 : Z ) ⩾ 3 := by linarith\n","```\n","\n","```\n","have h 17 : ( p - 1 : Z ) * ( q - 1 : Z ) ⩾ 2 := by nlinarith have h 18 : ( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z ) ⩾ 6 := by nlinarith have h 19 : ( k : Z ) * (( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z )) ⩾ 4 * (( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z )) := by nlinarith have h 20 : ( p * q * r - 1 : Z ) ⩾ 4 * (( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z )) := by linarith have h 21 : ( p * q * r - 1 : Z ) < 4 * (( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z )) := by have h 22 : ( p : Z ) * q * r < 4 * (( p - 1 : Z ) * ( q - 1 : Z ) * ( r - 1 : Z )) + 1 := by nlinarith [ mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 3 ), mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 4 ), mul_nonneg ( sub_nonneg mpr h . 3 ) ( sub_nonneg mpr h . 4 )] linarith linarith have h 13 : k = 1 ∨ k = 2 ∨ k = 3 := by omega -- We need to handle each case of k separately rcases h 13 with ( rfl | rfl | rfl ) · -- Case k = 1 have h 14 : p * q * r - 1 = ( p - 1) * ( q - 1) * ( r - 1) := by ring_nf at hk ⊢ <;> linarith have h 15 : p * q + p * r + q * r = p + q + r := by have h 151 : p * q * r - 1 = ( p - 1) * ( q - 1) * ( r - 1) := by linarith ring_nf at h 151 ⊢ nlinarith have h 16 : p = 2 := by by_contra h 16 have h 17 : p ⩾ 3 := by by_contra h 17 have h 18 : p ⩽ 2 := by linarith have h 19 : p = 2 := by linarith contradiction have h 20 : q ⩾ 3 := by linarith have h 21 : r ⩾ 4 := by linarith have h 22 : ( p : Z ) * q ⩾ 3 * 3 := by nlinarith have h 23 : ( p : Z ) * r ⩾ 3 * 4 := by nlinarith have h 24 : ( q : Z ) * r ⩾ 3 * 4 := by nlinarith nlinarith have h 17 : q = 3 := by by_contra h 17 have h 18 : q ⩾ 4 := by by_contra h 18 have h 19 : q ⩽ 3 := by linarith have h 20 : q = 3 := by linarith contradiction have h 21 : p = 2 := by linarith have h 22 : ( p : Z ) * q ⩾ 2 * 4 := by nlinarith have h 23 : ( p : Z ) * r ⩾ 2 * 4 := by nlinarith have h 24 : ( q : Z ) * r ⩾ 4 * 4 := by nlinarith nlinarith have h 18 : r = 4 := by by_contra h 18 have h 19 : r ⩾ 5 := by\n","```\n","\n","·\n","\n","```\n","by_contra h 19 have h 20 : r ⩽ 4 := by linarith have h 21 : r = 4 := by linarith contradiction have h 22 : p = 2 := by linarith have h 23 : q = 3 := by linarith have h 24 : ( p : Z ) * q ⩾ 2 * 3 := by nlinarith have h 25 : ( p : Z ) * r ⩾ 2 * 5 := by nlinarith have h 26 : ( q : Z ) * r ⩾ 3 * 5 := by nlinarith nlinarith exfalso norm_num [ h 16 , h 17 , h 18 ] at h 14 h 15 hk h 0 ⊢ <;> linarith -- Case k = 2 have h 14 : p * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by ring_nf at hk ⊢ <;> linarith have h 15 : p = 3 := by by_contra h 15 have h 16 : p ≠ 3 := by tauto -- We need to show that p cannot be greater than 3 have h 17 : p ⩾ 4 := by by_contra h 17 have h 18 : p ⩽ 3 := by linarith have h 19 : p = 2 := by by_contra h 19 have h 20 : p ⩾ 3 := by omega have h 21 : p = 3 := by omega contradiction have h 22 : p = 2 := by omega have h 23 : q ⩾ 3 := by linarith have h 24 : r ⩾ 4 := by linarith have h 25 : ( p : Z ) * q ⩾ 2 * 3 := by nlinarith have h 26 : ( p : Z ) * r ⩾ 2 * 4 := by nlinarith have h 27 : ( q : Z ) * r ⩾ 3 * 4 := by nlinarith have h 28 : ( p : Z ) * q * r ⩾ 2 * 3 * 4 := by nlinarith have h 29 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 30 : ( p : Z ) = 2 := by omega have h 31 : ( q : Z ) ⩾ 3 := by omega have h 32 : ( r : Z ) ⩾ 4 := by omega have h 33 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 34 : ( p : Z ) = 2 := by omega have h 35 : ( q : Z ) ⩾ 3 := by omega have h 36 : ( r : Z ) ⩾ 4 := by omega have h 37 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 38 : False := by have h 39 : ( p : Z ) = 2 := by omega have h 40 : ( q : Z ) ⩾ 3 := by omega have h 41 : ( r : Z ) ⩾ 4 := by omega have h 42 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 43 : 2 * q * r - 1 = 2 * (1 * ( q - 1) * ( r - 1)) := by simp [ h 39 ] at h 42 ⊢ <;> ring_nf at h 42 ⊢ <;> linarith have h 44 : 2 * q * r - 1 = 2 * (( q - 1) * ( r - 1)) := by ring_nf at h 43 ⊢ <;> linarith have h 45 : 2 * q * r - 1 = 2 * ( q * r -q -r + 1) := by ring_nf at h 44 ⊢ <;> linarith have h 46 : 2 * q * r - 1 = 2 * q * r - 2 * q - 2 * r + 2 := by ring_nf at h 45 ⊢ <;> linarith\n","```\n","\n","```\n","have h 47 : -1 = -2 * q - 2 * r + 2 := by linarith have h 48 : 2 * q + 2 * r = 3 := by linarith have h 49 : ( q : Z ) ⩾ 3 := by omega have h 50 : ( r : Z ) ⩾ 4 := by omega have h 51 : 2 * q + 2 * r ⩾ 14 := by nlinarith linarith exact h 38 have h 19 : q ⩾ p + 1 := by omega have h 20 : r ⩾ q + 1 := by omega have h 21 : ( p : Z ) ⩾ 4 := by omega have h 22 : ( q : Z ) ⩾ 5 := by omega have h 23 : ( r : Z ) ⩾ 6 := by omega have h 24 : ( p : Z ) * q ⩾ 4 * 5 := by nlinarith have h 25 : ( p : Z ) * r ⩾ 4 * 6 := by nlinarith have h 26 : ( q : Z ) * r ⩾ 5 * 6 := by nlinarith have h 27 : ( p : Z ) * q * r ⩾ 4 * 5 * 6 := by nlinarith have h 28 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 29 : ( p : Z ) ⩾ 4 := by omega have h 30 : ( q : Z ) ⩾ 5 := by omega have h 31 : ( r : Z ) ⩾ 6 := by omega have h 32 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 33 : False := by nlinarith [ sq_nonneg (( p : Z ) - 2), sq_nonneg (( q : Z ) - 2), sq_nonneg (( r : Z ) - 2), mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 3 ), mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 4 ), mul_nonneg ( sub_nonneg mpr h . 3 ) ( sub_nonneg mpr h . 4 )] exact h 33 have h 16 : q = 5 := by have h 17 : p = 3 := by linarith have h 18 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 19 : ( p : Z ) = 3 := by norm_num [ h 17 ] have h 20 : ( q : Z ) ⩾ 4 := by by_contra h 20 have h 21 : q ⩽ 3 := by linarith have h 22 : q = 3 := by linarith have h 23 : ( p : Z ) = 3 := by norm_num [ h 17 ] have h 24 : ( q : Z ) = 3 := by norm_num [ h 22 ] have h 25 : ( r : Z ) ⩾ 4 := by linarith norm_num [ h 17 , h 22 , h 23 , h 24 ] at h 18 <;> ( try omega ) <;> ( try nlinarith ) <;> ( try { nlinarith [ mul_pos ( sub_pos mpr h . 0 .2.1) ( sub_pos mpr h . 0 .2.2)] }) have h 21 : ( r : Z ) ⩾ q + 1 := by linarith have h 22 : ( q : Z ) ⩾ 4 := by linarith have h 23 : ( p : Z ) = 3 := by norm_num [ h 17 ] have h 24 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 25 : 3 * q * r - 1 = 2 * (2 * ( q - 1) * ( r - 1)) := by norm_num [ h 17 , h 19 ] at h 24 ⊢ <;> ring_nf at h 24 ⊢ <;> linarith have h 26 : 3 * q * r - 1 = 4 * (( q - 1) * ( r - 1)) := by ring_nf at h 25 ⊢ <;> nlinarith have h 27 : 3 * q * r - 1 = 4 * ( q * r -q -r + 1) := by ring_nf at h 26 ⊢ <;> nlinarith\n","```\n","\n","```\n","have h 28 : 3 * q * r - 1 = 4 * q * r - 4 * q - 4 * r + 4 := by ring_nf at h 27 ⊢ <;> nlinarith have h 29 : -q * r + 4 * q + 4 * r - 5 = 0 := by ring_nf at h 28 ⊢ <;> nlinarith have h 30 : ( q : Z ) * r - 4 * q - 4 * r + 5 = 0 := by ring_nf at h 29 ⊢ <;> nlinarith have h 31 : ( q - 4 : Z ) * ( r - 4 : Z ) = 11 := by ring_nf at h 30 ⊢ <;> nlinarith have h 32 : ( q : Z ) - 4 = 1 ∧ ( r : Z ) - 4 = 11 ∨ ( q : Z ) - 4 = 11 ∧ ( r : Z ) - 4 = 1 ∨ ( q : Z ) - 4 = -1 ∧ ( r : Z ) - 4 = -11 ∨ ( q : Z ) - 4 = -11 ∧ ( r : Z ) - 4 = -1 := by have h 33 : ( q : Z ) - 4 = 1 ∨ ( q : Z ) - 4 = 11 ∨ ( q : Z ) - 4 = -1 ∨ ( q : Z ) - 4 = -11 := by have h 34 : ( q : Z ) - 4 | 11 := by use ( r : Z ) - 4 linarith have h 35 : ( q : Z ) - 4 = 1 ∨ ( q : Z ) - 4 = 11 ∨ ( q : Z ) - 4 = -1 ∨ ( q : Z ) - 4 = -11 := by have h 36 : ( q : Z ) - 4 = 1 ∨ ( q : Z ) - 4 = 11 ∨ ( q : Z ) - 4 = -1 ∨ ( q : Z ) - 4 = -11 := by rw [ ← Int natAbs_dvd_natAbs . ] at h 34 -- We use the fact that the absolute value of (q - 4) divides the absolute value of 11 have h 37 : (( q : Z ) - 4). natAbs | 11 := by simpa [ Int natAbs . ] using h 34 -- Since the possible divisors of 11 are 1 and 11, we check the cases have h 38 : (( q : Z ) - 4). natAbs = 1 ∨ (( q : Z ) - 4). natAbs = 11 := by have h 39 : (( q : Z ) - 4). natAbs | 11 := h 37 have h 40 : (( q : Z ) - 4). natAbs ⩽ 11 := Nat le_of_dvd . ( by decide ) h 39 interval_cases (( q : Z ) - 4). natAbs <;> norm_num at h 39 ⊢ <;> omega cases h 38 with | inl h 38 => have h 41 : ( q : Z ) - 4 = 1 ∨ ( q : Z ) - 4 = -1 := by have h 42 : (( q : Z ) - 4). natAbs = 1 := h 38 have h 43 : ( q : Z ) - 4 = 1 ∨ ( q : Z ) - 4 = -1 := by rw [ Int natAbs_eq_iff . ] at h 42 tauto exact h 43 cases h 41 with | inl h 41 => tauto | inr h 41 => tauto | inr h 38 => have h 41 : ( q : Z ) - 4 = 11 ∨ ( q : Z ) - 4 = -11 := by have h 42 : (( q : Z ) - 4). natAbs = 11 := h 38 have h 43 : ( q : Z ) - 4 = 11 ∨ ( q : Z ) - 4 = -11 := by rw [ Int natAbs_eq_iff . ] at h 42 tauto exact h 43 cases h 41 with | inl h 41 => tauto | inr h 41 => tauto exact h 36 exact h 35 cases h 33 with | inl h 33 => have h 34 : ( q : Z ) - 4 = 1 := h 33 have h 35 : ( r : Z ) - 4 = 11 := by have h 36 : (( q : Z ) - 4) * (( r : Z ) - 4) = 11 := by\n","```\n","\n","```\n","linarith rw [ h 34 ] at h 36 linarith exact Or inl . ⟨ h 34 , h 35 ⟩ | inr h 33 => cases h 33 with | inl h 33 => have h 34 : ( q : Z ) - 4 = 11 := h 33 have h 35 : ( r : Z ) - 4 = 1 := by have h 36 : (( q : Z ) - 4) * (( r : Z ) - 4) = 11 := by linarith rw [ h 34 ] at h 36 linarith exact Or inr . ( Or inl . ⟨ h 34 , h 35 ⟩ ) | inr h 33 => cases h 33 with | inl h 33 => have h 34 : ( q : Z ) - 4 = -1 := h 33 have h 35 : ( r : Z ) - 4 = -11 := by have h 36 : (( q : Z ) - 4) * (( r : Z ) - 4) = 11 := by linarith rw [ h 34 ] at h 36 linarith exact Or inr . ( Or inr . ( Or inl . ⟨ h 34 , h 35 ⟩ )) | inr h 33 => have h 34 : ( q : Z ) - 4 = -11 := h 33 have h 35 : ( r : Z ) - 4 = -1 := by have h 36 : (( q : Z ) - 4) * (( r : Z ) - 4) = 11 := by linarith rw [ h 34 ] at h 36 linarith exact Or inr . ( Or inr . ( Or inr . ⟨ h 34 , h 35 ⟩ )) rcases h 32 with ( ⟨ h 32 , h 33 ⟩ | ⟨ h 32 , h 33 ⟩ | ⟨ h 32 , h 33 ⟩ | ⟨ h 32 , h 33 ⟩ ) · -- Case 1: q - 4 = 1 and r - 4 = 11 have h 34 : q = 5 := by linarith have h 35 : r = 15 := by linarith simp [ h 34 , h 35 , h 15 ] <;> norm_num <;> omega · -- Case 2: q - 4 = 11 and r - 4 = 1 have h 34 : q = 15 := by linarith have h 35 : r = 5 := by linarith have h 36 : r > q := by linarith linarith · -- Case 3: q - 4 = -1 and r - 4 = -11 have h 34 : q = 3 := by linarith have h 35 : r = -7 := by linarith have h 36 : r > q := by linarith linarith · -- Case 4: q - 4 = -11 and r - 4 = -1 have h 34 : q = -7 := by linarith have h 35 : r = 3 := by linarith\n","```\n","\n","·\n","\n","```\n","have h 36 : r > q := by linarith linarith have h 17 : r = 15 := by have h 18 : p = 3 := by linarith have h 19 : q = 5 := by linarith have h 20 : ( p : Z ) * q * r - 1 = 2 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 21 : ( p : Z ) = 3 := by norm_num [ h 18 ] have h 22 : ( q : Z ) = 5 := by norm_num [ h 19 ] norm_num [ h 18 , h 19 , h 21 , h 22 ] at h 20 <;> ring_nf at h 20 ⊢ <;> omega have h 18 : ( p q r , , ) = (3, 5, 15) := by simp_all [ Prod ext_iff . ] <;> norm_num <;> linarith exact Or inr h . 18 -- Case k = 3 have h 14 : p * q * r - 1 = 3 * (( p - 1) * ( q - 1) * ( r - 1)) := by ring_nf at hk ⊢ <;> linarith have h 15 : p = 2 := by by_contra h 15 have h 16 : p ⩾ 3 := by by_contra h 16 have h 17 : p ⩽ 2 := by linarith have h 18 : p = 2 := by linarith contradiction have h 19 : q ⩾ p + 1 := by linarith have h 20 : r ⩾ q + 1 := by linarith have h 21 : ( p : Z ) ⩾ 3 := by linarith have h 22 : ( q : Z ) ⩾ 4 := by linarith have h 23 : ( r : Z ) ⩾ 5 := by linarith have h 24 : ( p : Z ) * q ⩾ 3 * 4 := by nlinarith have h 25 : ( p : Z ) * r ⩾ 3 * 5 := by nlinarith have h 26 : ( q : Z ) * r ⩾ 4 * 5 := by nlinarith have h 27 : ( p : Z ) * q * r ⩾ 3 * 4 * 5 := by nlinarith have h 28 : ( p : Z ) * q * r - 1 = 3 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 29 : ( p : Z ) ⩾ 3 := by linarith have h 30 : ( q : Z ) ⩾ 4 := by linarith have h 31 : ( r : Z ) ⩾ 5 := by linarith have h 32 : ( p : Z ) * q * r - 1 = 3 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 33 : False := by nlinarith [ sq_nonneg (( p : Z ) - 2), sq_nonneg (( q : Z ) - 2), sq_nonneg (( r : Z ) - 2), mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 3 ), mul_nonneg ( sub_nonneg mpr h . 2 ) ( sub_nonneg mpr h . 4 ), mul_nonneg ( sub_nonneg mpr h . 3 ) ( sub_nonneg mpr h . 4 )] exact h 33 have h 16 : q = 4 := by have h 17 : p = 2 := by linarith have h 18 : ( p : Z ) * q * r - 1 = 3 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 19 : ( p : Z ) = 2 := by norm_num [ h 17 ] have h 20 : ( q : Z ) ⩾ 3 := by by_contra h 20 have h 21 : q ⩽ 2 := by linarith have h 22 : q = 2 := by linarith have h 23 : ( p : Z ) = 2 := by norm_num [ h 17 ] have h 24 : ( q : Z ) = 2 := by norm_num [ h 22 ] have h 25 : ( r : Z ) ⩾ 3 := by linarith norm_num [ h 17 , h 22 , h 23 , h 24 ] at h 18 <;> ( try omega ) <;> ( try nlinarith ) <;>\n","```\n","\n","```\n","( try { nlinarith [ mul_pos ( sub_pos mpr h . 0 .2.1) ( sub_pos mpr h . 0 .2.2)] }) have h 21 : ( r : Z ) ⩾ q + 1 := by linarith have h 22 : ( q : Z ) ⩾ 3 := by linarith have h 23 : ( p : Z ) = 2 := by norm_num [ h 17 ] have h 24 : ( p : Z ) * q * r - 1 = 3 * (( p - 1) * ( q - 1) * ( r - 1)) := by linarith have h 25 : 2 * q * r - 1 = 3 * (1 * ( q - 1) * ( r - 1)) := by norm_num [ h 17 , h 19 ] at h 24 ⊢ <;> ring_nf at h 24 ⊢ <;> linarith have h 26 : 2 * q * r - 1 = 3 * (( q - 1) * ( r - 1)) := by ring_nf at h 25 ⊢ <;> nlinarith have h 27 : 2 * q * r - 1 = 3 * ( q * r -q -r + 1) := by ring_nf at h 26 ⊢ <;> nlinarith have h 28 : 2 * q * r - 1 = 3 * q * r - 3 * q - 3 * r + 3 := by ring_nf at h 27 ⊢ <;> nlinarith have h 29 : -q * r + 3 * q + 3 * r - 4 = 0 := by ring_nf at h 28 ⊢ <;> nlinarith have h 30 : ( q : Z ) * r - 3 * q - 3 * r + 4 = 0 := by ring_nf at h 29 ⊢ <;> nlinarith have h 31 : ( q - 3 : Z ) * ( r - 3 : Z ) = 5 := by ring_nf at h 30 ⊢ <;> nlinarith have h 32 : ( q : Z ) - 3 = 1 ∧ ( r : Z ) - 3 = 5 ∨ ( q : Z ) - 3 = 5 ∧ ( r : Z ) - 3 = 1 ∨ ( q : Z ) - 3 = -1 ∧ ( r : Z ) - 3 = -5 ∨ ( q : Z ) - 3 = -5 ∧ ( r : Z ) - 3 = -1 := by have h 33 : ( q : Z ) - 3 = 1 ∨ ( q : Z ) - 3 = 5 ∨ ( q : Z ) - 3 = -1 ∨ ( q : Z ) - 3 = -5 := by have h 34 : ( q : Z ) - 3 | 5 := by use ( r : Z ) - 3 linarith have h 35 : ( q : Z ) - 3 = 1 ∨ ( q : Z ) - 3 = 5 ∨ ( q : Z ) - 3 = -1 ∨ ( q : Z ) - 3 = -5 := by have h 36 : ( q : Z ) - 3 = 1 ∨ ( q : Z ) - 3 = 5 ∨ ( q : Z ) - 3 = -1 ∨ ( q : Z ) - 3 = -5 := by rw [ ← Int natAbs_dvd_natAbs . ] at h 34 -- We use the fact that the absolute value of (q - 3) divides the absolute value of 5 have h 37 : (( q : Z ) - 3). natAbs | 5 := by simpa [ Int natAbs . ] using h 34 -- Since the possible divisors of 5 are 1 and 5, we check the cases have h 38 : (( q : Z ) - 3). natAbs = 1 ∨ (( q : Z ) - 3). natAbs = 5 := by have h 39 : (( q : Z ) - 3). natAbs | 5 := h 37 have h 40 : (( q : Z ) - 3). natAbs ⩽ 5 := Nat le_of_dvd . ( by decide ) h 39 interval_cases (( q : Z ) - 3). natAbs <;> norm_num at h 39 ⊢ <;> omega cases h 38 with | inl h 38 => have h 41 : ( q : Z ) - 3 = 1 ∨ ( q : Z ) - 3 = -1 := by have h 42 : (( q : Z ) - 3). natAbs = 1 := h 38 have h 43 : ( q : Z ) - 3 = 1 ∨ ( q : Z ) - 3 = -1 := by rw [ Int natAbs_eq_iff . ] at h 42 tauto exact h 43 cases h 41 with | inl h 41 => tauto | inr h 41 => tauto | inr h 38 => have h 41 : ( q : Z ) - 3 = 5 ∨ ( q : Z ) - 3 = -5 := by\n","```\n","\n","```\n","have h 42 : (( q : Z ) - 3). natAbs = 5 := h 38 have h 43 : ( q : Z ) - 3 = 5 ∨ ( q : Z ) - 3 = -5 := by rw [ Int natAbs_eq_iff . ] at h 42 tauto exact h 43 cases h 41 with | inl h 41 => tauto | inr h 41 => tauto exact h 36 exact h 35 cases h 33 with | inl h 33 => have h 34 : ( q : Z ) - 3 = 1 := h 33 have h 35 : ( r : Z ) - 3 = 5 := by have h 36 : (( q : Z ) - 3) * (( r : Z ) - 3) = 5 := by linarith rw [ h 34 ] at h 36 linarith exact Or inl . ⟨ h 34 , h 35 ⟩ | inr h 33 => cases h 33 with | inl h 33 => have h 34 : ( q : Z ) - 3 = 5 := h 33 have h 35 : ( r : Z ) - 3 = 1 := by have h 36 : (( q : Z ) - 3) * (( r : Z ) - 3) = 5 := by linarith rw [ h 34 ] at h 36 linarith exact Or inr . ( Or inl . ⟨ h 34 , h 35 ⟩ ) | inr h 33 => cases h 33 with | inl h 33 => have h 34 : ( q : Z ) - 3 = -1 := h 33 have h 35 : ( r : Z ) - 3 = -5 := by have h 36 : (( q : Z ) - 3) * (( r : Z ) - 3) = 5 := by linarith rw [ h 34 ] at h 36 linarith exact Or inr . ( Or inr . ( Or inl . ⟨ h 34 , h 35 ⟩ )) | inr h 33 => have h 34 : ( q : Z ) - 3 = -5 := h 33 have h 35 : ( r : Z ) - 3 = -1 := by have h 36 : (( q : Z ) - 3) * (( r : Z ) - 3) = 5 := by linarith rw [ h 34 ] at h 36 linarith exact Or inr . ( Or inr . ( Or inr . ⟨ h 34 , h 35 ⟩ )) rcases h 32 with ( ⟨ h 32 , h 33 ⟩ | ⟨ h 32 , h 33 ⟩ | ⟨ h 32 , h 33 ⟩ | ⟨ h 32 , h 33 ⟩ ) · -- Case 1: q - 3 = 1 and r - 3 = 5 have h 34 : q = 4 := by linarith have h 35 : r = 8 := by linarith simp [ h 34 , h 35 , h 15 ] <;> norm_num <;> omega · -- Case 2: q - 3 = 5 and r - 3 = 1 have h 34 : q = 8 := by linarith have h 35 : r = 4 := by\n","```\n","\n","```\n","linarith have h 36 : r > q := by linarith linarith · -- Case 3: q - 3 = -1 and r - 3 = -5 have h 34 : q = 2 := by linarith have h 35 : r = -2 := by linarith have h 36 : r > q := by linarith linarith · -- Case 4: q - 3 = -5 and r - 3 = -1 have h 34 : q = -2 := by linarith have h 35 : r = 2 := by linarith have h 36 : r > q := by linarith linarith have h 17 : r = 8 := by have h 18 : p = 2 := by linarith have h 19 : q = 4 := by linarith have h 20 : ( p : Z ) * q * r - 1 = 3 * (( p - 1) * ( q - 1) * ( r - 1)) := have h 21 : ( p : Z ) = 2 := by norm_num [ h 18 ] have h 22 : ( q : Z ) = 4 := by norm_num [ h 19 ] norm_num [ h 18 , h 19 , h 21 , h 22 ] at h 20 <;> ring_nf at h 20 ⊢ <;> omega have h 18 : ( p q r , , ) = (2, 4, 8) := by simp_all [ Prod ext_iff . ] <;> norm_num <;> linarith exact Or inl h . 18 exact h 5\n","```\n","\n","```\n","by linarith '''\n","```\n","\n","## B. Examples of the Proofs Generated by DeepSeek-Prover-V2-7B on PutnamBench\n","\n","```\n","import Mathlib open Nat Set /--Let 𝐻 be an 𝑛 × 𝑛 matrix all of whose entries are ± 1 and whose rows are mutually orthogonal. Suppose 𝐻 has an 𝑎 × 𝑏 submatrix whose entries are all 1. Show that 𝑎𝑏 ⩽ 𝑛 . -/ theorem putnam_2005_a4 ( n : N ) ( H : Matrix ( Fin n ) ( Fin n ) R ) ( a b : N ) ( S : Matrix ( Fin a ) ( Fin b ) R ) ( npos : n ⩾ 1) ( Hentries : ∀ i j : Fin n H i j , = 1 ∨ H i j = -1) ( Hortho : H HasOrthogonalRows . ) ( hab : 1 ⩽ a ∧ a ⩽ n ∧ 1 ⩽ b ∧ b ⩽ n ) ( Ssub : ∃ ( rri : Fin a → Fin n ) ( cri : Fin b → Fin n ), rri Injective . ∧ cri Injective . ∧ S = H submatrix . rri cri ) ( Sentries : ∀ ( i : Fin a ) ( j : Fin b ), S i j = 1) : a * b ⩽ n := by\n","```\n","\n","```\n","obtain ⟨ rri cri hrinj hcrij hsub , , , , ⟩ := Ssub have h 1 : a ⩽ n := hab .2.1 have h 2 : b ⩽ n := hab .2.2.2 have h 3 : a * b ⩽ n := by calc a * b = Cardinal toNat . ( a * b ) := by simp [ Nat cast_inj . _ ⩽ Cardinal toNat . ( n ) := by apply ? _ = n := by simp [ Nat cast_inj . ]\n","```\n","\n","```\n","] exact h 3\n","```\n","\n","↦\n","\n","↦\n","\n","```\n","import Mathlib open Set Nat Function -- fun n → 2 ^ (n + 1) /--Let 𝑛 be a positive integer. Find the number of pairs 𝑃 𝑄 , of polynomials with real coefficients such that \\[ (P(X))^2 + (Q(X))^2 = X^{2n} + 1 \\] and deg 𝑃 > deg 𝑄 . -/ theorem putnam_2007_b4 ( n : N ) ( npos : n > 0) : ({( P Q , ) : ( Polynomial R ) × ( Polynomial R ) | P ^ 2 + Q ^ 2 = Polynomial X . ^ (2 * n ) + 1 ∧ P degree . > Q degree . }. ncard = (( fun n → 2 ^ ( n + 1)) : N → N ) n ) := by have h 1 : ∀ n : N , n > 0 → ({ ( P Q , ) : ( Polynomial R ) × ( Polynomial R ) | P ^ 2 + Q ^ 2 = Polynomial X . ^ (2 * n ) + 1 ∧ P degree . > Q degree . }. ncard : N ) = 2 ^ ( n + 1) := by intro n hn have h : ∀ n : N , n > 0 → ({ ( P Q , ) : ( Polynomial R ) × ( Polynomial R ) | P ^ 2 + Q ^ 2 = Polynomial X . ^ (2 * n ) + 1 ∧ P degree . > Q degree . }. ncard : N ) = 2 ^ ( n + 1) := by intro n hn have h 1 : ({ ( P Q , ) : ( Polynomial R ) × ( Polynomial R ) | P ^ 2 + Q ^ 2 = Polynomial X . ^ (2 * n ) + 1 ∧ P degree . > Q degree . }. ncard : N ) = 2 ^ ( n + 1) := by have h 2 : ({ ( P Q , ) : ( Polynomial R ) × ( Polynomial R ) | P ^ 2 + Q ^ 2 = Polynomial X . ^ (2 * n ) + 1 ∧ P degree . > Q degree . } : Set (( Polynomial R ) × ( Polynomial R ))). ncard = 2 ^ ( n + 1) := by rw [ ← Cardinal natCast_inj . ] apply ? exact_mod_cast h 2 exact h 1 exact h n hn have h 2 : ({ ( P Q , ) : ( Polynomial R ) × ( Polynomial R ) | P ^ 2 + Q ^ 2 = Polynomial X . ^ (2 * n ) + 1 ∧ P degree . > Q degree . }. ncard : N ) = 2 ^ ( n + 1) := by apply h 1 exact npos simpa [ h 2 ] using h 2\n","```\n","\n","## C. Revision to MiniF2F\n","\n","- 1. mathd\\_algebra\\_247 :\n","\n","```\n","/-- Let 𝑡 = 2 𝑠 -𝑠 2 and 𝑠 = 𝑛 2 -2 𝑛 + 1. What is the value of 𝑡 when 𝑛 = 3? Show that it is 0.-/ theorem mathd_algebra_247 ( t s : R ) ( n : Z ) ( h 0 : t = 2 * s -s ^ 2) ( h 1 : s = n ^ 2 - 2 ^ n + 1) ( n ) ( _ : n = 3) : t = 0 := by sorry -- revise to theorem mathd_algebra_247 ( t s : R ) ( n : Z ) ( h 0 : t = 2 * s -s ^ 2) ( h 1 : s = n ^ 2 - 2 ^ n + 1)\n","```\n","\n","```\n","( _ : n = 3) : t = 0 := by sorry\n","```\n","\n","```\n","/-- Show that for positive integer 𝑛 , ˝ 𝑛 -1 𝑘 = 0 ( 2 𝑘 + 1 ) = 𝑛 2 .-/ theorem induction_sum_odd ( n : N ) : ( ˝ k in Finset range n . , 2 * k ) + 1 = n ^ 2 := by sorry -- revise to theorem induction_sum_odd ( n : N ) : ( ˝ k in Finset range n . , (2 * k + 1)) = n ^ 2 := by sorry\n","```\n","\n","## 2. induction\\_sum\\_odd : 3. induction\\_prod1p1onk3le3m1onn :\n","\n","```\n","/-- Show that for any positive integer 𝑛 , we have ˛ 𝑛 𝑘 = 1 ( 1 + 1 / 𝑘 3 ) ⩽ 3 -1 / 𝑛 .-/ theorem induction_prod1p1onk3le3m1onn ( n : N ) ( h 0 : 0 < n ) : ( ˛ k in Finset Icc . 1 n , 1 + (1 : R ) / k ^ 3) ⩽ (3 : R ) - 1 / ↑ n := by sorry -- revise to theorem induction_prod1p1onk3le3m1onn ( n : N ) ( h 0 : 0 < n ) : ( ˛ k in Finset Icc . 1 n , (1 + (1 : R ) / k ^ 3)) ⩽ (3 : R ) - 1 / ↑ n := by sorry\n","```\n"]}]}]}